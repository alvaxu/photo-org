"""
å›¾åƒç‰¹å¾æå–æœåŠ¡

åŸºäºResNet50æ¨¡å‹æå–å›¾åƒç‰¹å¾å‘é‡

## åŠŸèƒ½ç‰¹ç‚¹ï¼š
1. å»¶è¿ŸåŠ è½½PyTorchå’ŒResNet50æ¨¡å‹
2. æ”¯æŒæœ¬åœ°æ¨¡å‹å’Œåœ¨çº¿æ¨¡å‹
3. æ”¯æŒHEICæ ¼å¼ï¼ˆé€šè¿‡PILï¼‰
4. æå–2048ç»´ç‰¹å¾å‘é‡
5. è‡ªåŠ¨L2å½’ä¸€åŒ–

## ä¸å…¶ä»–ç‰ˆæœ¬çš„ä¸åŒç‚¹ï¼š
- å‚è€ƒäººè„¸è¯†åˆ«æœåŠ¡çš„æ¶æ„è®¾è®¡
- ä½¿ç”¨å¼‚æ­¥å¤„ç†æé«˜æ€§èƒ½
- æ”¯æŒæ‰¹é‡ç‰¹å¾æå–
"""

import asyncio
import json
import logging
from typing import Optional, List, Dict
from pathlib import Path
from datetime import datetime
import numpy as np
import imagehash  # ç”¨äºperceptual_hashç›¸ä¼¼åº¦è®¡ç®—

# å»¶è¿Ÿå¯¼å…¥é‡å‹åº“
torch = None
torchvision = None
PIL = None
Image = None
transforms = None
models = None
HEIC_SUPPORT = False
orjson = None  # å¿«é€ŸJSONåº“

def _lazy_import_dependencies():
    """å»¶è¿Ÿå¯¼å…¥é‡å‹åº“"""
    global torch, torchvision, PIL, Image, transforms, models, HEIC_SUPPORT, orjson
    
    if torch is None:
        try:
            import torch
            import torchvision
            from torchvision import models, transforms
            from PIL import Image
            import PIL
            logging.info("âœ… æˆåŠŸåŠ è½½å›¾åƒç‰¹å¾æå–ä¾èµ–åº“")
            
            # HEICæ”¯æŒ
            try:
                from pillow_heif import register_heif_opener
                register_heif_opener()
                HEIC_SUPPORT = True
            except ImportError:
                HEIC_SUPPORT = False
                logging.warning("pillow-heifæœªå®‰è£…ï¼ŒHEICæ ¼å¼æ”¯æŒå—é™")
                
        except ImportError as e:
            logging.error(f"å›¾åƒç‰¹å¾æå–ä¾èµ–å¯¼å…¥å¤±è´¥: {e}")
    
    # å»¶è¿Ÿå¯¼å…¥orjsonï¼ˆå¿«é€ŸJSONåº“ï¼‰
    # æ³¨æ„ï¼šorjsonä¼šåœ¨é¦–æ¬¡ä½¿ç”¨æ—¶è‡ªåŠ¨å¯¼å…¥ï¼ˆåœ¨_fast_json_loads/_fast_json_dumpsä¸­ï¼‰
    # è¿™é‡Œä¸å¼ºåˆ¶å¯¼å…¥ï¼Œå…è®¸ç³»ç»Ÿåœ¨orjsonä¸å¯ç”¨æ—¶ç»§ç»­è¿è¡Œ

from app.core.config import settings
from app.db.session import get_db
from app.models.photo import Photo
from app.core.logging import get_logger
from sqlalchemy.orm import Session

logger = get_logger(__name__)


def _fast_json_loads(json_str: str) -> list:
    """
    å¿«é€ŸJSONè§£æï¼ˆä½¿ç”¨orjsonï¼Œå¦‚æœå¯ç”¨ï¼‰
    
    :param json_str: JSONå­—ç¬¦ä¸²
    :return: è§£æåçš„Pythonå¯¹è±¡
    """
    global orjson
    
    # å¦‚æœorjsonè¿˜æœªå¯¼å…¥ï¼Œå°è¯•å¯¼å…¥
    if orjson is None:
        try:
            import orjson
            logger.debug("æˆåŠŸåŠ è½½orjsonå¿«é€ŸJSONåº“")
        except ImportError:
            orjson = False  # æ ‡è®°ä¸ºä¸å¯ç”¨ï¼Œé¿å…é‡å¤å°è¯•
            return json.loads(json_str)
    
    # å¦‚æœorjsonå¯ç”¨ï¼Œä½¿ç”¨å®ƒ
    if orjson is not False:
        try:
            return orjson.loads(json_str)
        except Exception as e:
            logger.warning(f"orjsonè§£æå¤±è´¥ï¼Œå›é€€åˆ°æ ‡å‡†json: {str(e)}")
            return json.loads(json_str)
    else:
        return json.loads(json_str)


def _fast_json_dumps(obj) -> str:
    """
    å¿«é€ŸJSONåºåˆ—åŒ–ï¼ˆä½¿ç”¨orjsonï¼Œå¦‚æœå¯ç”¨ï¼‰
    
    :param obj: è¦åºåˆ—åŒ–çš„Pythonå¯¹è±¡
    :return: JSONå­—ç¬¦ä¸²
    """
    global orjson
    
    # å¦‚æœorjsonè¿˜æœªå¯¼å…¥ï¼Œå°è¯•å¯¼å…¥
    if orjson is None:
        try:
            import orjson
            logger.debug("æˆåŠŸåŠ è½½orjsonå¿«é€ŸJSONåº“")
        except ImportError:
            orjson = False  # æ ‡è®°ä¸ºä¸å¯ç”¨ï¼Œé¿å…é‡å¤å°è¯•
            return json.dumps(obj, separators=(',', ':'))
    
    # å¦‚æœorjsonå¯ç”¨ï¼Œä½¿ç”¨å®ƒ
    if orjson is not False:
        try:
            # orjsonè¿”å›bytesï¼Œéœ€è¦è§£ç ä¸ºå­—ç¬¦ä¸²
            return orjson.dumps(obj, option=orjson.OPT_SERIALIZE_NUMPY).decode('utf-8')
        except Exception as e:
            logger.warning(f"orjsonåºåˆ—åŒ–å¤±è´¥ï¼Œå›é€€åˆ°æ ‡å‡†json: {str(e)}")
            return json.dumps(obj, separators=(',', ':'))
    else:
        return json.dumps(obj, separators=(',', ':'))


class ImageFeatureService:
    """å›¾åƒç‰¹å¾æå–æœåŠ¡ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–å›¾åƒç‰¹å¾æå–æœåŠ¡"""
        self.model = None
        self.preprocess = None
        self.is_initialized = False
        self.config = settings.image_features
        # æ³¨æ„ï¼šä¸å†åœ¨ __init__ ä¸­å›ºå®š storage_baseï¼Œæ”¹ä¸ºåŠ¨æ€è¯»å–
    
    @property
    def storage_base(self) -> Path:
        """åŠ¨æ€è·å–å­˜å‚¨åŸºç¡€è·¯å¾„ï¼ˆæ¯æ¬¡ä½¿ç”¨æ—¶è¯»å–æœ€æ–°é…ç½®ï¼‰"""
        from app.core.config import get_settings
        from app.core.path_utils import resolve_resource_path
        return resolve_resource_path(get_settings().storage.base_path)
    
    def _get_full_path(self, image_path: str) -> Path:
        """
        æ„å»ºå®Œæ•´çš„æ–‡ä»¶è·¯å¾„
        
        :param image_path: ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„
        :return: å®Œæ•´è·¯å¾„
        """
        path = Path(image_path)
        if path.is_absolute():
            return path
        return self.storage_base / image_path
    
    async def initialize(self) -> bool:
        """
        åˆå§‹åŒ–ResNet50æ¨¡å‹
        
        :return: æ˜¯å¦åˆå§‹åŒ–æˆåŠŸ
        """
        # å»¶è¿Ÿå¯¼å…¥ä¾èµ–
        _lazy_import_dependencies()
        
        try:
            if not torch:
                logger.error("PyTorchæœªå®‰è£…ï¼Œæ— æ³•å¯ç”¨å›¾åƒç‰¹å¾æå–")
                return False
            
            if not self.config.enabled:
                logger.info("å›¾åƒç‰¹å¾æå–åŠŸèƒ½å·²ç¦ç”¨")
                return False
            
            logger.info("ğŸ”„ æ­£åœ¨åˆå§‹åŒ–ResNet50æ¨¡å‹...")
            
            # æ ¹æ®é…ç½®å†³å®šä½¿ç”¨æœ¬åœ°æ¨¡å‹è¿˜æ˜¯åœ¨çº¿æ¨¡å‹
            if self.config.use_local_model:
                # ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„è·¯å¾„è§£æå‡½æ•°ï¼‰
                from app.core.path_utils import resolve_resource_path
                models_base_path = resolve_resource_path(self.config.models_base_path)
                model_file_path = models_base_path / self.config.model_file
                logger.info(f"ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„: {model_file_path}")
                
                if not model_file_path.exists():
                    logger.error(f"æœ¬åœ°æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_file_path}")
                    return False
                
                # åŠ è½½ResNet50æ¨¡å‹
                # å…ˆåˆ›å»ºå®Œæ•´çš„æ¨¡å‹ç»“æ„
                model = models.resnet50(weights=None)
                
                # ä»æœ¬åœ°æ–‡ä»¶åŠ è½½é¢„è®­ç»ƒæƒé‡
                state_dict = torch.load(str(model_file_path), map_location='cpu')
                model.load_state_dict(state_dict)
                logger.info("âœ… æˆåŠŸä»æœ¬åœ°æ–‡ä»¶åŠ è½½æ¨¡å‹æƒé‡")
            else:
                # ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼ˆåœ¨çº¿ä¸‹è½½ï¼‰
                logger.info(f"ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹: {self.config.model}")
                model = models.resnet50(weights='IMAGENET1K_V2')
            
            # ç§»é™¤åˆ†ç±»å±‚ï¼Œåªä¿ç•™ç‰¹å¾æå–éƒ¨åˆ†
            # ç§»é™¤æœ€åä¸¤å±‚ï¼šavgpoolå’Œfc
            backbone = torch.nn.Sequential(*list(model.children())[:-2])
            
            # æ·»åŠ å…¨å±€å¹³å‡æ± åŒ–å±‚ï¼Œå°†ç‰¹å¾å›¾è½¬æ¢ä¸ºå‘é‡
            # ç»“æ„ï¼šbackbone -> AdaptiveAvgPool2d -> Flatten
            self.model = torch.nn.Sequential(
                backbone,
                torch.nn.AdaptiveAvgPool2d((1, 1)),  # å…¨å±€å¹³å‡æ± åŒ–ï¼š7x7 -> 1x1
                torch.nn.Flatten()  # å±•å¹³ï¼š1x1x2048 -> 2048
            )
            
            # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
            self.model.eval()
            
            # å®šä¹‰å›¾åƒé¢„å¤„ç†
            self.preprocess = transforms.Compose([
                transforms.Resize(256),
                transforms.CenterCrop(224),
                transforms.ToTensor(),
                transforms.Normalize(
                    mean=[0.485, 0.456, 0.406],
                    std=[0.229, 0.224, 0.225]
                )
            ])
            
            self.is_initialized = True
            logger.info("âœ… ResNet50æ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼Œå·²å°±ç»ª")
            return True
            
        except Exception as e:
            logger.error(f"ResNet50æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def extract_features(self, image_path: str) -> Optional[np.ndarray]:
        """
        æå–å•å¼ ç…§ç‰‡çš„ç‰¹å¾å‘é‡
        
        :param image_path: ç…§ç‰‡è·¯å¾„ï¼ˆç›¸å¯¹æˆ–ç»å¯¹ï¼‰
        :return: ç‰¹å¾å‘é‡ï¼ˆ2048ç»´ï¼Œå·²å½’ä¸€åŒ–ï¼‰ï¼Œå¤±è´¥è¿”å›None
        """
        if not self.is_initialized:
            logger.error("æ¨¡å‹æœªåˆå§‹åŒ–")
            return None
        
        try:
            full_path = self._get_full_path(image_path)
            
            if not full_path.exists():
                logger.error(f"ç…§ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {full_path}")
                return None
            
            # åŠ è½½å›¾åƒï¼ˆæ”¯æŒHEICï¼‰
            if full_path.suffix.lower() in ['.heic', '.heif'] and HEIC_SUPPORT:
                from pillow_heif import read_heif
                heif_file = read_heif(full_path)
                image = Image.frombytes(
                    heif_file.mode,
                    heif_file.size,
                    heif_file.data,
                    "raw",
                    heif_file.mode,
                    heif_file.stride,
                )
            else:
                image = Image.open(full_path)
            
            # è½¬æ¢ä¸ºRGB
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # é¢„å¤„ç†å¹¶æ·»åŠ æ‰¹æ¬¡ç»´åº¦
            input_tensor = self.preprocess(image)
            input_batch = input_tensor.unsqueeze(0)
            
            # æå–ç‰¹å¾ï¼ˆæ¨¡å‹å·²åŒ…å«å…¨å±€å¹³å‡æ± åŒ–å’Œå±•å¹³ï¼‰
            with torch.no_grad():
                feature = self.model(input_batch)  # [1, 2048]
            
            # ç§»é™¤batchç»´åº¦å¹¶è½¬æ¢ä¸ºnumpy
            feature = feature.squeeze(0)  # [2048]
            feature_vector = feature.numpy()
            
            # L2å½’ä¸€åŒ–
            feature_vector = feature_vector / np.linalg.norm(feature_vector)
            
            return feature_vector
            
        except Exception as e:
            logger.error(f"æå–ç‰¹å¾å¤±è´¥ {image_path}: {str(e)}")
            import traceback
            traceback.print_exc()
            return None
    
    def save_features_to_db(self, photo_id: int, features: np.ndarray, db_session: Session) -> bool:
        """
        ä¿å­˜ç‰¹å¾å‘é‡åˆ°æ•°æ®åº“
        
        :param photo_id: ç…§ç‰‡ID
        :param features: ç‰¹å¾å‘é‡ï¼ˆnumpyæ•°ç»„ï¼‰
        :param db_session: æ•°æ®åº“ä¼šè¯
        :return: æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            photo = db_session.query(Photo).filter(Photo.id == photo_id).first()
            if not photo:
                logger.error(f"ç…§ç‰‡ {photo_id} ä¸å­˜åœ¨")
                return False
            
            # åºåˆ—åŒ–ä¸ºJSONï¼ˆä½¿ç”¨å¿«é€ŸJSONåº“ï¼‰
            features_json = _fast_json_dumps(features.tolist())
            
            # æ›´æ–°æ•°æ®åº“
            photo.image_features = features_json
            photo.image_features_extracted = True
            photo.image_features_extracted_at = datetime.now()
            
            db_session.commit()
            logger.debug(f"âœ… ç‰¹å¾å‘é‡å·²ä¿å­˜åˆ°æ•°æ®åº“ (photo_id: {photo_id})")
            return True
            
        except Exception as e:
            logger.error(f"ä¿å­˜ç‰¹å¾å‘é‡å¤±è´¥ {photo_id}: {str(e)}")
            db_session.rollback()
            import traceback
            traceback.print_exc()
            return False
    
    def batch_save_features_to_db(self, features_data: List[Dict], db_session: Session) -> int:
        """
        æ‰¹é‡ä¿å­˜ç‰¹å¾å‘é‡åˆ°æ•°æ®åº“
        
        :param features_data: ç‰¹å¾æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« {'photo_id': int, 'features': np.ndarray}
        :param db_session: æ•°æ®åº“ä¼šè¯
        :return: æˆåŠŸä¿å­˜çš„æ•°é‡
        """
        if not features_data:
            return 0
        
        try:
            # è·å–æ‰€æœ‰ç…§ç‰‡ID
            photo_ids = [item['photo_id'] for item in features_data]
            photos = db_session.query(Photo).filter(Photo.id.in_(photo_ids)).all()
            photo_dict = {photo.id: photo for photo in photos}
            
            saved_count = 0
            current_time = datetime.now()
            
            for item in features_data:
                photo_id = item['photo_id']
                features = item['features']
                
                photo = photo_dict.get(photo_id)
                if not photo:
                    logger.warning(f"ç…§ç‰‡ {photo_id} ä¸å­˜åœ¨ï¼Œè·³è¿‡ä¿å­˜")
                    continue
                
                try:
                    # åºåˆ—åŒ–ä¸ºJSON
                    features_json = json.dumps(features.tolist(), separators=(',', ':'))
                    
                    # æ›´æ–°æ•°æ®åº“
                    photo.image_features = features_json
                    photo.image_features_extracted = True
                    photo.image_features_extracted_at = current_time
                    
                    saved_count += 1
                except Exception as e:
                    logger.error(f"ä¿å­˜ç…§ç‰‡ {photo_id} ç‰¹å¾å‘é‡å¤±è´¥: {str(e)}")
                    continue
            
            # æ‰¹é‡æäº¤
            db_session.commit()
            logger.info(f"âœ… æ‰¹é‡ä¿å­˜ {saved_count}/{len(features_data)} ä¸ªç‰¹å¾å‘é‡åˆ°æ•°æ®åº“")
            return saved_count
            
        except Exception as e:
            logger.error(f"æ‰¹é‡ä¿å­˜ç‰¹å¾å‘é‡å¤±è´¥: {str(e)}")
            db_session.rollback()
            import traceback
            traceback.print_exc()
            return 0
    
    def load_features_from_db(self, photo: Photo) -> Optional[np.ndarray]:
        """
        ä»æ•°æ®åº“åŠ è½½ç‰¹å¾å‘é‡
        
        :param photo: ç…§ç‰‡å¯¹è±¡
        :return: ç‰¹å¾å‘é‡ï¼ˆnumpyæ•°ç»„ï¼‰ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            if not photo.image_features:
                return None
            
            # ååºåˆ—åŒ–JSONï¼ˆä½¿ç”¨å¿«é€ŸJSONåº“ï¼‰
            features_list = _fast_json_loads(photo.image_features)
            features = np.array(features_list)
            
            return features
            
        except Exception as e:
            logger.error(f"åŠ è½½ç‰¹å¾å‘é‡å¤±è´¥ {photo.id}: {str(e)}")
            return None
    
    def calculate_cosine_similarity(self, features1: np.ndarray, features2: np.ndarray) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªç‰¹å¾å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦
        
        :param features1: ç¬¬ä¸€ä¸ªç‰¹å¾å‘é‡
        :param features2: ç¬¬äºŒä¸ªç‰¹å¾å‘é‡
        :return: ç›¸ä¼¼åº¦ï¼ˆ0-1ï¼‰
        """
        try:
            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            dot_product = np.dot(features1, features2)
            norm1 = np.linalg.norm(features1)
            norm2 = np.linalg.norm(features2)
            
            if norm1 == 0 or norm2 == 0:
                return 0.0
            
            similarity = dot_product / (norm1 * norm2)
            return float(similarity)
            
        except Exception as e:
            logger.error(f"è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦å¤±è´¥: {str(e)}")
            return 0.0
    
    def _calculate_perceptual_hash_similarity(self, hash1: str, hash2: str) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªperceptual_hashçš„ç›¸ä¼¼åº¦ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼šç›´æ¥è®¡ç®—æ±‰æ˜è·ç¦»ï¼Œé¿å…hashå¯¹è±¡è½¬æ¢ï¼‰
        
        :param hash1: ç¬¬ä¸€ä¸ªå“ˆå¸Œå€¼ï¼ˆ16è¿›åˆ¶å­—ç¬¦ä¸²ï¼‰
        :param hash2: ç¬¬äºŒä¸ªå“ˆå¸Œå€¼ï¼ˆ16è¿›åˆ¶å­—ç¬¦ä¸²ï¼‰
        :return: ç›¸ä¼¼åº¦ï¼ˆ0-1ï¼‰
        """
        try:
            if not hash1 or not hash2:
                return 0.0
            
            # æ£€æŸ¥å“ˆå¸Œé•¿åº¦æ˜¯å¦ä¸€è‡´
            if len(hash1) != len(hash2):
                return 0.0
            
            # ä¼˜åŒ–ï¼šç›´æ¥è®¡ç®—æ±‰æ˜è·ç¦»ï¼Œé¿å…hashå¯¹è±¡è½¬æ¢
            # å°†16è¿›åˆ¶å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ•´æ•°ï¼Œç„¶åä½¿ç”¨XORè®¡ç®—æ±‰æ˜è·ç¦»
            try:
                # è½¬æ¢ä¸ºæ•´æ•°
                int1 = int(hash1, 16)
                int2 = int(hash2, 16)
                
                # ä½¿ç”¨XORè®¡ç®—ä¸åŒä½ï¼Œç„¶åç»Ÿè®¡1çš„ä¸ªæ•°ï¼ˆæ±‰æ˜è·ç¦»ï¼‰
                xor_result = int1 ^ int2
                # ä½¿ç”¨æœ€å¿«çš„ä½è®¡æ•°æ–¹æ³•ï¼ˆPython 3.10+æœ‰bit_count()ï¼Œå¦åˆ™ä½¿ç”¨bin().count()ï¼‰
                if hasattr(int, 'bit_count'):
                    hamming_dist = xor_result.bit_count()
                else:
                    hamming_dist = bin(xor_result).count('1')
            except ValueError:
                # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œå›é€€åˆ°ä½¿ç”¨imagehashåº“
                h1 = imagehash.hex_to_hash(hash1)
                h2 = imagehash.hex_to_hash(hash2)
                hamming_dist = h1 - h2
            
            # æ ¹æ®å“ˆå¸Œé•¿åº¦è®¾ç½®æœ€å¤§è·ç¦»
            # perceptual_hashé€šå¸¸æ˜¯16ä¸ªå­—ç¬¦çš„16è¿›åˆ¶å­—ç¬¦ä¸²ï¼Œæ¯ä¸ªå­—ç¬¦4ä½ï¼Œæ€»å…±64ä½
            max_distance = len(hash1) * 4  # æ¯ä¸ªå­—ç¬¦4ä½
            if max_distance == 0:
                return 0.0
            
            # è½¬æ¢ä¸ºç›¸ä¼¼åº¦ï¼ˆ0-1ï¼‰
            similarity = max(0.0, 1 - (hamming_dist / max_distance))
            return similarity
            
        except Exception as e:
            logger.warning(f"è®¡ç®—perceptual_hashç›¸ä¼¼åº¦å¤±è´¥: {str(e)}")
            return 0.0
    
    def find_similar_photos_by_features(
        self,
        db_session: Session,
        reference_photo_id: int,
        threshold: float = 0.7,
        limit: int = 20
    ) -> List[Dict]:
        """
        åŸºäºç‰¹å¾å‘é‡æœç´¢ç›¸ä¼¼ç…§ç‰‡ï¼ˆå‘é‡åŒ–ä¼˜åŒ–ç‰ˆæœ¬ + perceptual_hashé¢„ç­›é€‰ï¼‰
        
        ä½¿ç”¨perceptual_hashè¿›è¡Œé¢„ç­›é€‰ï¼Œå¤§å¹…å‡å°‘éœ€è¦è®¡ç®—ç‰¹å¾å‘é‡ç›¸ä¼¼åº¦çš„ç…§ç‰‡æ•°é‡
        ç„¶åä½¿ç”¨numpyå‘é‡åŒ–è®¡ç®—ï¼Œè¿›ä¸€æ­¥æå‡å¤§æ•°æ®é‡ä¸‹çš„æœç´¢æ€§èƒ½
        å¯¹äº40000å¼ ç…§ç‰‡ï¼Œæ€§èƒ½æå‡å¯è¾¾5-10å€
        
        :param db_session: æ•°æ®åº“ä¼šè¯
        :param reference_photo_id: å‚è€ƒç…§ç‰‡ID
        :param threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰
        :param limit: è¿”å›æ•°é‡é™åˆ¶
        :return: ç›¸ä¼¼ç…§ç‰‡åˆ—è¡¨
        """
        try:
            logger.info(f"[ç‰¹å¾åˆ†æç›¸ä¼¼æœç´¢] å¼€å§‹æœç´¢ç›¸ä¼¼ç…§ç‰‡ï¼Œå‚è€ƒç…§ç‰‡ID: {reference_photo_id}, é˜ˆå€¼: {threshold}, é™åˆ¶: {limit}")
            
            # è·å–å‚è€ƒç…§ç‰‡ï¼ˆéœ€è¦åŒ…å«perceptual_hashå­—æ®µï¼‰
            reference_photo = db_session.query(Photo).filter(Photo.id == reference_photo_id).first()
            if not reference_photo:
                logger.error(f"[ç‰¹å¾åˆ†æç›¸ä¼¼æœç´¢] å‚è€ƒç…§ç‰‡ {reference_photo_id} ä¸å­˜åœ¨")
                return []
            
            # æ£€æŸ¥å‚è€ƒç…§ç‰‡æ˜¯å¦æœ‰perceptual_hashï¼ˆé¢„ç­›é€‰å¿…éœ€ï¼‰
            if not reference_photo.perceptual_hash:
                logger.warning(f"[ç‰¹å¾åˆ†æç›¸ä¼¼æœç´¢] å‚è€ƒç…§ç‰‡ {reference_photo_id} æ²¡æœ‰perceptual_hashï¼Œæ— æ³•ä½¿ç”¨é¢„ç­›é€‰ä¼˜åŒ–")
                # å¯ä»¥é€‰æ‹©é™çº§åˆ°ä¸ä½¿ç”¨é¢„ç­›é€‰ï¼Œä½†ä¸ºäº†ä¿æŒä¸€è‡´æ€§ï¼Œè¿”å›ç©ºç»“æœ
                # æç¤ºç”¨æˆ·å…ˆè¿›è¡ŒåŸºç¡€åˆ†æä»¥ç”Ÿæˆperceptual_hash
                return []
            
            # åŠ è½½å‚è€ƒç…§ç‰‡çš„ç‰¹å¾å‘é‡
            reference_features = self.load_features_from_db(reference_photo)
            if reference_features is None:
                logger.warning(f"å‚è€ƒç…§ç‰‡ {reference_photo_id} æ²¡æœ‰ç‰¹å¾å‘é‡")
                return []
            
            # ç¡®ä¿å‚è€ƒç‰¹å¾å‘é‡æ˜¯numpyæ•°ç»„ä¸”ä¸º1D
            reference_features = np.array(reference_features).flatten()
            
            # ä»é…ç½®æ–‡ä»¶è¯»å–perceptual_hashé¢„ç­›é€‰é˜ˆå€¼ï¼ˆå¤ç”¨æ™ºèƒ½åˆ†æçš„é…ç½®ï¼‰
            hash_threshold = settings.similarity.first_layer_thresholds.get('perceptual_hash', 0.4)
            logger.info(f"[ç‰¹å¾åˆ†æç›¸ä¼¼æœç´¢] ä½¿ç”¨perceptual_hashé¢„ç­›é€‰é˜ˆå€¼: {hash_threshold}")
            
            # è·å–æ‰€æœ‰å·²æå–ç‰¹å¾ä¸”æœ‰perceptual_hashçš„ç…§ç‰‡ï¼ˆæ’é™¤å‚è€ƒç…§ç‰‡ï¼‰
            # æŸ¥è¯¢å®Œæ•´çš„Photoå¯¹è±¡ï¼Œä»¥ä¾¿åœ¨APIå±‚ç›´æ¥ä½¿ç”¨
            photos_with_features = db_session.query(Photo).filter(
                Photo.id != reference_photo_id,
                Photo.image_features_extracted == True,
                Photo.image_features.isnot(None),
                Photo.perceptual_hash.isnot(None),  # ç”¨äºé¢„ç­›é€‰
                Photo.perceptual_hash != ''  # æ’é™¤ç©ºå­—ç¬¦ä¸²
            ).all()
            
            logger.info(f"[ç‰¹å¾åˆ†æç›¸ä¼¼æœç´¢] æŸ¥è¯¢åˆ°æœ‰ç‰¹å¾å‘é‡å’Œperceptual_hashçš„ç…§ç‰‡æ•°: {len(photos_with_features)}")
            
            if not photos_with_features:
                logger.info("[ç‰¹å¾åˆ†æç›¸ä¼¼æœç´¢] æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„å€™é€‰ç…§ç‰‡")
                return []
            
            # perceptual_hashé¢„ç­›é€‰ï¼šå…ˆå¿«é€Ÿè¿‡æ»¤æ‰æ˜æ˜¾ä¸ç›¸ä¼¼çš„ç…§ç‰‡
            logger.info(f"[ç‰¹å¾åˆ†æç›¸ä¼¼æœç´¢] å¼€å§‹perceptual_hashé¢„ç­›é€‰ï¼Œå€™é€‰ç…§ç‰‡æ•°: {len(photos_with_features)}")
            reference_hash = reference_photo.perceptual_hash
            pre_screened_photos = []
            
            for photo in photos_with_features:
                # è®¡ç®—perceptual_hashç›¸ä¼¼åº¦
                hash_sim = self._calculate_perceptual_hash_similarity(reference_hash, photo.perceptual_hash)
                
                # å¦‚æœç›¸ä¼¼åº¦ä½äºé˜ˆå€¼ï¼Œè·³è¿‡è¯¥ç…§ç‰‡ï¼ˆä¸å†è¿›è¡Œç‰¹å¾å‘é‡è®¡ç®—ï¼‰
                if hash_sim < hash_threshold:
                    continue
                
                # é€šè¿‡é¢„ç­›é€‰ï¼Œä¿ç•™è¯¥ç…§ç‰‡
                pre_screened_photos.append(photo)
            
            filter_rate = (1 - len(pre_screened_photos) / len(photos_with_features)) * 100 if photos_with_features else 0
            logger.info(f"[ç‰¹å¾åˆ†æç›¸ä¼¼æœç´¢] perceptual_hashé¢„ç­›é€‰å®Œæˆï¼Œé€šè¿‡ç­›é€‰: {len(pre_screened_photos)}/{len(photos_with_features)} (è¿‡æ»¤ç‡: {filter_rate:.1f}%)")
            
            if not pre_screened_photos:
                logger.info("[ç‰¹å¾åˆ†æç›¸ä¼¼æœç´¢] é¢„ç­›é€‰åæ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„ç…§ç‰‡")
                return []
            
            # æ‰¹é‡åŠ è½½æ‰€æœ‰é€šè¿‡é¢„ç­›é€‰çš„ç…§ç‰‡çš„ç‰¹å¾å‘é‡åˆ°numpyçŸ©é˜µï¼ˆå‘é‡åŒ–ä¼˜åŒ– + å¿«é€ŸJSONè§£æï¼‰
            photo_objects = []  # å­˜å‚¨Photoå¯¹è±¡å¼•ç”¨
            feature_matrix = []
            
            # æ‰¹é‡è§£æJSONï¼ˆä½¿ç”¨å¿«é€ŸJSONåº“ï¼‰
            reference_dim = reference_features.shape[0]
            logger.info(f"[ç‰¹å¾åˆ†æç›¸ä¼¼æœç´¢] å¼€å§‹åŠ è½½ç‰¹å¾å‘é‡ï¼Œç…§ç‰‡æ•°: {len(pre_screened_photos)}")
            for photo in pre_screened_photos:
                try:
                    # è·³è¿‡ç©ºçš„ç‰¹å¾å‘é‡
                    if not photo.image_features:
                        continue
                    
                    # ä½¿ç”¨å¿«é€ŸJSONè§£æï¼ˆorjsonæ¯”æ ‡å‡†jsonå¿«3-5å€ï¼‰
                    features_list = _fast_json_loads(photo.image_features)
                    features = np.array(features_list, dtype=np.float32).flatten()
                    
                    # éªŒè¯ç‰¹å¾å‘é‡ç»´åº¦
                    if features.shape[0] != reference_dim:
                        logger.warning(f"ç…§ç‰‡ {photo.id} ç‰¹å¾å‘é‡ç»´åº¦ä¸åŒ¹é…: {features.shape[0]} vs {reference_dim}")
                        continue
                    
                    # ä¿ç•™Photoå¯¹è±¡å¼•ç”¨
                    photo_objects.append(photo)
                    feature_matrix.append(features)
                    
                except Exception as e:
                    logger.warning(f"åŠ è½½ç…§ç‰‡ {photo.id} ç‰¹å¾å‘é‡å¤±è´¥: {str(e)}")
                    continue
            
            if not feature_matrix:
                return []
            
            # è½¬æ¢ä¸ºnumpyçŸ©é˜µï¼ˆN x feature_dimï¼‰
            # ä½¿ç”¨float32å‡å°‘å†…å­˜å ç”¨ï¼ˆ2048ç»´ç‰¹å¾å‘é‡ï¼Œfloat32è¶³å¤Ÿç²¾ç¡®ï¼‰
            feature_matrix = np.array(feature_matrix, dtype=np.float32)
            
            # å‘é‡åŒ–è®¡ç®—æ‰€æœ‰ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆä¸€æ¬¡æ€§è®¡ç®—ï¼Œé¿å…å¾ªç¯ï¼‰
            # å‚è€ƒå‘é‡å½’ä¸€åŒ–
            ref_norm = np.linalg.norm(reference_features)
            if ref_norm == 0:
                logger.warning("å‚è€ƒç‰¹å¾å‘é‡ä¸ºé›¶å‘é‡")
                return []
            
            # è®¡ç®—æ‰€æœ‰ç…§ç‰‡ç‰¹å¾å‘é‡çš„L2èŒƒæ•°
            feature_norms = np.linalg.norm(feature_matrix, axis=1)
            
            # é¿å…é™¤é›¶é”™è¯¯
            valid_mask = feature_norms > 0
            if not np.any(valid_mask):
                return []
            
            # è®¡ç®—ç‚¹ç§¯ï¼ˆçŸ©é˜µä¹˜æ³•ï¼šN x feature_dim @ feature_dim = Nï¼‰
            dot_products = np.dot(feature_matrix[valid_mask], reference_features)
            
            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆå‘é‡åŒ–ï¼‰
            similarities = dot_products / (feature_norms[valid_mask] * ref_norm)
            
            # ç­›é€‰æ»¡è¶³é˜ˆå€¼çš„ç»“æœ
            threshold_mask = similarities >= threshold
            
            # è·å–æ»¡è¶³æ¡ä»¶çš„ç´¢å¼•
            valid_indices = np.where(valid_mask)[0]
            
            if not np.any(threshold_mask):
                # é™çº§ç­–ç•¥ï¼šå¦‚æœæ²¡æœ‰æ»¡è¶³é˜ˆå€¼çš„ç…§ç‰‡ï¼Œè¿”å›ç›¸ä¼¼åº¦æœ€é«˜çš„1å¼ 
                if len(valid_indices) > 0:
                    # å¯¹æ‰€æœ‰æœ‰æ•ˆç…§ç‰‡æŒ‰ç›¸ä¼¼åº¦æ’åº
                    all_similarities = similarities[valid_mask]
                    sorted_indices = np.argsort(all_similarities)[::-1]  # é™åºæ’åº
                    # åªå–ç›¸ä¼¼åº¦æœ€é«˜çš„1å¼ 
                    top_idx = valid_indices[sorted_indices[0]]
                    similar_photos = [{
                        'photo': photo_objects[top_idx],
                        'similarity': float(all_similarities[sorted_indices[0]])
                    }]
                    logger.info(f"[ç‰¹å¾åˆ†æç›¸ä¼¼æœç´¢] æ²¡æœ‰æ»¡è¶³é˜ˆå€¼çš„ç…§ç‰‡ï¼Œé™çº§è¿”å›ç›¸ä¼¼åº¦æœ€é«˜çš„1å¼ ï¼ˆç›¸ä¼¼åº¦: {all_similarities[sorted_indices[0]]:.3f}ï¼‰")
                    return similar_photos
                else:
                    return []
            
            threshold_indices = valid_indices[threshold_mask]
            threshold_similarities = similarities[threshold_mask]
            
            # ä½¿ç”¨numpyçš„argsortè¿›è¡Œæ’åºï¼ˆæ¯”Pythonæ’åºå¿«ï¼‰
            sorted_indices = np.argsort(threshold_similarities)[::-1]  # é™åºæ’åº
            
            # é™åˆ¶è¿”å›æ•°é‡
            result_indices = sorted_indices[:limit]
            
            # æ„å»ºç»“æœåˆ—è¡¨ï¼ˆè¿”å›åŒ…å«Photoå¯¹è±¡çš„å­—å…¸ï¼Œä¸æ™ºèƒ½æœç´¢æ ¼å¼ä¸€è‡´ï¼‰
            similar_photos = []
            for idx in result_indices:
                photo_idx = threshold_indices[idx]
                similar_photos.append({
                    'photo': photo_objects[photo_idx],  # ä¿ç•™Photoå¯¹è±¡å¼•ç”¨
                    'similarity': float(threshold_similarities[idx])
                })
            
            logger.info(f"[ç‰¹å¾åˆ†æç›¸ä¼¼æœç´¢] æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(similar_photos)} å¼ ç›¸ä¼¼ç…§ç‰‡ï¼ˆé˜ˆå€¼: {threshold}ï¼‰")
            return similar_photos
            
        except Exception as e:
            logger.error(f"æœç´¢ç›¸ä¼¼ç…§ç‰‡å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return []


# å…¨å±€æœåŠ¡å®ä¾‹
image_feature_service = ImageFeatureService()

