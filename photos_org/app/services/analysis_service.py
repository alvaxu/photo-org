"""
å®¶åº­ç‰ˆæ™ºèƒ½ç…§ç‰‡ç³»ç»Ÿ - æ™ºèƒ½åˆ†ææœåŠ¡
"""
import os
import asyncio
import json
from typing import Dict, List, Optional, Any
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
from sqlalchemy.orm import Session
from app.core.logging import get_logger
from app.core.config import settings
from app.db.session import get_db
from app.models.photo import Photo, PhotoAnalysis, PhotoQuality
from app.services.dashscope_service import DashScopeService
from app.services.photo_quality_service import PhotoQualityService
from app.services.duplicate_detection_service import DuplicateDetectionService


class AnalysisService:
    """
    æ™ºèƒ½åˆ†ææœåŠ¡ç±»
    æ•´åˆå„ç§åˆ†æåŠŸèƒ½ï¼Œæä¾›ç»Ÿä¸€çš„åˆ†ææ¥å£
    """

    def __init__(self):
        """åˆå§‹åŒ–åˆ†ææœåŠ¡"""
        self.logger = get_logger(__name__)
        # æ‡’åŠ è½½ï¼šä¸ç«‹å³å®ä¾‹åŒ–æœåŠ¡ï¼Œé¦–æ¬¡ä½¿ç”¨æ—¶æ‰åˆ›å»º
        self._dashscope_service = None
        self._quality_service = None
        self._duplicate_service = None
        
        # çº¿ç¨‹æ± ç”¨äºå¹¶å‘å¤„ç†
        self.executor = ThreadPoolExecutor(max_workers=2)
    
    @property
    def dashscope_service(self):
        """è·å–DashScopeæœåŠ¡å®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self._dashscope_service is None:
            self._dashscope_service = DashScopeService()
        return self._dashscope_service
    
    @property
    def quality_service(self):
        """è·å–è´¨é‡è¯„ä¼°æœåŠ¡å®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self._quality_service is None:
            self._quality_service = PhotoQualityService()
        return self._quality_service
    
    @property
    def duplicate_service(self):
        """è·å–é‡å¤æ£€æµ‹æœåŠ¡å®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self._duplicate_service is None:
            self._duplicate_service = DuplicateDetectionService()
        return self._duplicate_service

    async def analyze_photo(self, photo_id: int, analysis_types: List[str] = None, db: Session = None, original_status: str = None) -> Dict[str, Any]:
        """
        åˆ†æå•å¼ ç…§ç‰‡

        Args:
            photo_id: ç…§ç‰‡ID
            analysis_types: åˆ†æç±»å‹åˆ—è¡¨ ['content', 'quality', 'duplicate']ï¼Œå¦‚æœä¸ºNoneåˆ™æ‰§è¡Œæ‰€æœ‰åˆ†æ
            db: æ•°æ®åº“ä¼šè¯ï¼Œå¦‚æœä¸ºNoneåˆ™åˆ›å»ºæ–°çš„

        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        # æ ‡è®°æ˜¯å¦éœ€è¦å…³é—­æ•°æ®åº“ä¼šè¯
        should_close_db = False
        
        try:
            # å¦‚æœæ²¡æœ‰ä¼ å…¥æ•°æ®åº“ä¼šè¯ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„
            if db is None:
                db = next(get_db())
                should_close_db = True
                
            photo = db.query(Photo).filter(Photo.id == photo_id).first()

            if not photo:
                raise Exception("ç…§ç‰‡ä¸å­˜åœ¨")

            if not photo.original_path:
                raise Exception("ç…§ç‰‡è·¯å¾„ä¸ºç©º")
            
            # æ„å»ºå®Œæ•´çš„æ–‡ä»¶è·¯å¾„
            storage_base = Path(settings.storage.base_path)
            full_path = storage_base / photo.original_path
            
            if not full_path.exists():
                raise Exception(f"ç…§ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {full_path}")

            # self.logger.info(f"å¼€å§‹åˆ†æç…§ç‰‡ {photo_id}: {photo.filename}, åˆ†æç±»å‹: {analysis_types}")

            # æ ¹æ®åˆ†æç±»å‹æœ‰æ¡ä»¶åœ°æ‰§è¡Œåˆ†æ
            tasks = []
            task_indices = {}  # è®°å½•ä»»åŠ¡åœ¨resultsæ•°ç»„ä¸­çš„ç´¢å¼•

            if analysis_types is None or 'content' in analysis_types:
                tasks.append(self._analyze_content_async(str(full_path)))
                task_indices['content'] = len(tasks) - 1

            if analysis_types is None or 'quality' in analysis_types:
                tasks.append(self._analyze_quality_async(str(full_path)))
                task_indices['quality'] = len(tasks) - 1

            # æ³¨æ„ï¼šduplicateåˆ†æå·²è¢«ç§»é™¤ï¼Œå› ä¸ºæ„ŸçŸ¥å“ˆå¸Œåœ¨å¯¼å…¥æ—¶å·²è®¡ç®—

            if not tasks:
                self.logger.warning(f"æ²¡æœ‰æœ‰æ•ˆçš„åˆ†æç±»å‹: {analysis_types}")
                return {"photo_id": photo_id, "message": "æ²¡æœ‰æœ‰æ•ˆçš„åˆ†æç±»å‹"}

            # ç­‰å¾…æ‰€æœ‰åˆ†æå®Œæˆ
            results = await asyncio.gather(*tasks, return_exceptions=True)

            # æ ¹æ®ä»»åŠ¡ç´¢å¼•å¤„ç†ç»“æœ
            content_result = None
            quality_result = None

            if 'content' in task_indices:
                content_idx = task_indices['content']
                if isinstance(results[content_idx], Exception):
                    # å†…å®¹åˆ†æå¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
                    raise results[content_idx]
                content_result = results[content_idx]

            if 'quality' in task_indices:
                quality_idx = task_indices['quality']
                if isinstance(results[quality_idx], Exception):
                    # è´¨é‡åˆ†æå¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
                    raise results[quality_idx]
                quality_result = results[quality_idx]

            hash_result = None  # æ„ŸçŸ¥å“ˆå¸Œå·²åœ¨å¯¼å…¥æ—¶è®¡ç®—ï¼Œä¸å†é‡å¤è®¡ç®—

            # ä¿å­˜åˆ†æç»“æœåˆ°æ•°æ®åº“
            analysis_result = self._save_analysis_results(
                photo_id, content_result, quality_result, hash_result, db, original_status
            )

            # self.logger.info(f"ç…§ç‰‡ {photo_id} åˆ†æå®Œæˆ")
            return analysis_result

        except Exception as e:
            self.logger.error(f"ç…§ç‰‡åˆ†æå¤±è´¥ {photo_id}: {str(e)}")
            raise Exception(f"ç…§ç‰‡åˆ†æå¤±è´¥: {str(e)}")
        finally:
            # å¦‚æœåˆ›å»ºäº†æ–°çš„æ•°æ®åº“ä¼šè¯ï¼Œéœ€è¦å…³é—­å®ƒ
            if should_close_db and db is not None:
                db.close()

    async def _analyze_content_async(self, image_path: str) -> Dict[str, Any]:
        """
        å¼‚æ­¥åˆ†æç…§ç‰‡å†…å®¹

        Args:
            image_path: ç…§ç‰‡æ–‡ä»¶è·¯å¾„

        Returns:
            å†…å®¹åˆ†æç»“æœ
        """
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            self.executor,
            self.dashscope_service.analyze_photo_content,
            image_path
        )

    async def _analyze_quality_async(self, image_path: str) -> Dict[str, Any]:
        """
        å¼‚æ­¥åˆ†æç…§ç‰‡è´¨é‡

        Args:
            image_path: ç…§ç‰‡æ–‡ä»¶è·¯å¾„

        Returns:
            è´¨é‡åˆ†æç»“æœ
        """
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            self.executor,
            self.quality_service.assess_quality,
            image_path
        )


    def _save_analysis_results(self, photo_id: int, content_result: Optional[Dict],
                            quality_result: Optional[Dict], hash_result: Optional[str],
                            db, original_status: str = None) -> Dict[str, Any]:
        """
        ä¿å­˜åˆ†æç»“æœåˆ°æ•°æ®åº“

        Args:
            photo_id: ç…§ç‰‡ID
            content_result: å†…å®¹åˆ†æç»“æœ
            quality_result: è´¨é‡åˆ†æç»“æœ
            hash_result: å“ˆå¸Œç»“æœ
            db: æ•°æ®åº“ä¼šè¯

        Returns:
            ä¿å­˜çš„åˆ†æç»“æœ
        """
        try:
            # ä¿å­˜å†…å®¹åˆ†æç»“æœ - æ£€æŸ¥æ˜¯å¦å­˜åœ¨ï¼Œå­˜åœ¨åˆ™æ›´æ–°ï¼Œå¦åˆ™åˆ›å»º
            if content_result:
                existing_content_analysis = db.query(PhotoAnalysis).filter(
                    PhotoAnalysis.photo_id == photo_id,
                    PhotoAnalysis.analysis_type == "content"
                ).first()

                if existing_content_analysis:
                    # æ›´æ–°ç°æœ‰è®°å½•
                    existing_content_analysis.analysis_result = content_result
                    existing_content_analysis.confidence_score = content_result.get("confidence", 0.0)
                    existing_content_analysis.updated_at = datetime.now()
                else:
                    # åˆ›å»ºæ–°è®°å½•
                    analysis_record = PhotoAnalysis(
                        photo_id=photo_id,
                        analysis_type="content",
                        analysis_result=content_result,
                        confidence_score=content_result.get("confidence", 0.0)
                    )
                    db.add(analysis_record)

            # ä¿å­˜è´¨é‡åˆ†æç»“æœ - æ£€æŸ¥æ˜¯å¦å­˜åœ¨ï¼Œå­˜åœ¨åˆ™æ›´æ–°ï¼Œå¦åˆ™åˆ›å»º
            if quality_result:
                existing_quality_analysis = db.query(PhotoQuality).filter(
                    PhotoQuality.photo_id == photo_id
                ).first()

                if existing_quality_analysis:
                    # æ›´æ–°ç°æœ‰è®°å½•
                    existing_quality_analysis.quality_score = quality_result.get("quality_score")
                    existing_quality_analysis.sharpness_score = quality_result.get("sharpness_score")
                    existing_quality_analysis.brightness_score = quality_result.get("brightness_score")
                    existing_quality_analysis.contrast_score = quality_result.get("contrast_score")
                    existing_quality_analysis.color_score = quality_result.get("color_score")
                    existing_quality_analysis.composition_score = quality_result.get("composition_score")
                    existing_quality_analysis.quality_level = quality_result.get("quality_level")
                    # å°†listè½¬æ¢ä¸ºdictæ ¼å¼å­˜å‚¨ï¼ˆå…¼å®¹ChineseFriendlyJSONï¼‰
                    technical_issues = quality_result.get("technical_issues", [])
                    if isinstance(technical_issues, list):
                        existing_quality_analysis.technical_issues = {"issues": technical_issues, "count": len(technical_issues), "has_issues": len(technical_issues) > 0}
                    else:
                        existing_quality_analysis.technical_issues = technical_issues
                    existing_quality_analysis.assessed_at = datetime.now()
                else:
                    # åˆ›å»ºæ–°è®°å½•
                    technical_issues = quality_result.get("technical_issues", [])
                    if isinstance(technical_issues, list):
                        technical_issues_data = {"issues": technical_issues, "count": len(technical_issues), "has_issues": len(technical_issues) > 0}
                    else:
                        technical_issues_data = technical_issues

                    quality_record = PhotoQuality(
                        photo_id=photo_id,
                        quality_score=quality_result.get("quality_score"),
                        sharpness_score=quality_result.get("sharpness_score"),
                        brightness_score=quality_result.get("brightness_score"),
                        contrast_score=quality_result.get("contrast_score"),
                        color_score=quality_result.get("color_score"),
                        composition_score=quality_result.get("composition_score"),
                        quality_level=quality_result.get("quality_level"),
                        technical_issues=technical_issues_data
                    )
                    db.add(quality_record)

            # æ™ºèƒ½çŠ¶æ€æ›´æ–°ï¼šæ ¹æ®åˆ†æç»“æœå’ŒåŸå§‹çŠ¶æ€å†³å®šæœ€ç»ˆçŠ¶æ€
            photo = db.query(Photo).filter(Photo.id == photo_id).first()
            if photo:
                # ä½¿ç”¨åŸå§‹çŠ¶æ€è€Œä¸æ˜¯å½“å‰çŠ¶æ€ï¼ˆå½“å‰çŠ¶æ€æ˜¯analyzingï¼‰
                base_status = original_status if original_status else photo.status
                new_status = base_status  # é»˜è®¤ä¿æŒåŸå§‹çŠ¶æ€
                
                # æ ¹æ®åˆ†æç»“æœå†³å®šæ–°çŠ¶æ€
                if quality_result and content_result:
                    new_status = 'completed'  # ä¸¤ç§åˆ†æéƒ½æˆåŠŸ
                elif quality_result:
                    # åŸºç¡€åˆ†ææˆåŠŸ
                    if base_status == 'content_completed':
                        new_status = 'completed'  # ä¹‹å‰AIåˆ†æå·²æˆåŠŸï¼Œç°åœ¨åŸºç¡€åˆ†æä¹ŸæˆåŠŸ
                    elif base_status == 'completed':
                        new_status = 'completed'  # ä¹‹å‰å·²å®Œæˆï¼Œç°åœ¨åŸºç¡€åˆ†æä¹ŸæˆåŠŸï¼Œä¿æŒcompleted
                    else:
                        new_status = 'quality_completed'  # ä»…åŸºç¡€åˆ†ææˆåŠŸ
                elif content_result:
                    # AIåˆ†ææˆåŠŸ
                    if base_status == 'quality_completed':
                        new_status = 'completed'  # ä¹‹å‰åŸºç¡€åˆ†æå·²æˆåŠŸï¼Œç°åœ¨AIåˆ†æä¹ŸæˆåŠŸ
                    elif base_status == 'completed':
                        new_status = 'completed'  # ä¹‹å‰å·²å®Œæˆï¼Œç°åœ¨AIåˆ†æä¹ŸæˆåŠŸï¼Œä¿æŒcompleted
                    else:
                        new_status = 'content_completed'  # ä»…AIåˆ†ææˆåŠŸ
                
                # æ›´æ–°çŠ¶æ€
                photo.status = new_status
                photo.updated_at = datetime.now()
                self.logger.info(f"ç…§ç‰‡ {photo_id} çŠ¶æ€ä» {base_status} æ›´æ–°ä¸º: {new_status}")

            # å…ˆæäº¤åˆ†æç»“æœåˆ°æ•°æ®åº“
            db.commit()

            # æ ¹æ®åˆ†æç±»å‹è°ƒç”¨ç›¸åº”çš„æ ‡ç­¾å’Œåˆ†ç±»ç”ŸæˆæœåŠ¡
            try:
                from app.services.classification_service import ClassificationService
                classification_service = ClassificationService()

                # å¦‚æœæœ‰è´¨é‡åˆ†æç»“æœï¼Œç”ŸæˆåŸºç¡€æ ‡ç­¾å’Œè®¾å¤‡åˆ†ç±»
                if quality_result:
                    # æ¸…ç†ç°æœ‰çš„åŸºç¡€æ ‡ç­¾ï¼ˆé¿å…æ ‡ç­¾ç´¯ç§¯ï¼‰- ä½¿ç”¨å­æŸ¥è¯¢é¿å…join+deleteé—®é¢˜
                    # æ³¨æ„ï¼šä¸å†æ¸…ç†'device'æ ‡ç­¾ï¼Œå› ä¸ºç›¸æœºå“ç‰Œå’Œå‹å·å·²å­˜å‚¨åœ¨photoè¡¨ä¸­
                    from app.models.photo import PhotoTag, Tag
                    tag_ids_to_delete = db.query(PhotoTag.id).join(Tag).filter(
                        PhotoTag.photo_id == photo_id,
                        PhotoTag.source == 'auto',
                        Tag.category.in_(['time', 'lens', 'aperture', 'focal_length'])
                    ).subquery()
                    db.query(PhotoTag).filter(PhotoTag.id.in_(tag_ids_to_delete)).delete(synchronize_session=False)

                    basic_tags = classification_service.generate_basic_tags(photo, quality_result, db)
                    basic_classifications = classification_service.generate_basic_classifications(photo)

                    # ä¿å­˜åŸºç¡€æ ‡ç­¾
                    if basic_tags:
                        saved_basic_tags = classification_service._save_auto_tags(photo_id, basic_tags, db)

                    # ä¿å­˜åŸºç¡€åˆ†ç±»
                    if basic_classifications:
                        saved_basic_categories = classification_service._save_classifications(photo_id, basic_classifications, db)

                # å¦‚æœæœ‰å†…å®¹åˆ†æç»“æœï¼Œç”ŸæˆAIæ ‡ç­¾å’Œå†…å®¹åˆ†ç±»
                if content_result:
                    # æ¸…ç†ç°æœ‰çš„AIæ ‡ç­¾ï¼ˆé¿å…æ ‡ç­¾ç´¯ç§¯ï¼‰- ä½¿ç”¨å­æŸ¥è¯¢é¿å…join+deleteé—®é¢˜
                    from app.models.photo import PhotoTag, Tag
                    from sqlalchemy import select
                    tag_ids_to_delete = db.query(PhotoTag.id).join(Tag).filter(
                        PhotoTag.photo_id == photo_id,
                        PhotoTag.source == 'auto',
                        Tag.category.in_(['scene', 'activity', 'emotion', 'object'])
                    ).subquery()
                    # ä½¿ç”¨ select() æ˜¾å¼åŒ…è£…å­æŸ¥è¯¢
                    db.query(PhotoTag).filter(PhotoTag.id.in_(select(tag_ids_to_delete.c.id))).delete(synchronize_session=False)

                    # æ¸…ç†ç°æœ‰çš„AIåˆ†ç±»ï¼ˆé¿å…åˆ†ç±»ç´¯ç§¯ï¼‰
                    from app.models.photo import PhotoCategory
                    db.query(PhotoCategory).filter(PhotoCategory.photo_id == photo_id).delete()

                    ai_tags = classification_service.generate_ai_tags(content_result)
                    ai_classifications = classification_service.generate_ai_classifications(photo, content_result)

                    # ä¿å­˜AIæ ‡ç­¾
                    if ai_tags:
                        saved_ai_tags = classification_service._save_auto_tags(photo_id, ai_tags, db)

                    # ä¿å­˜AIåˆ†ç±»
                    if ai_classifications:
                        saved_ai_categories = classification_service._save_classifications(photo_id, ai_classifications, db)

            except Exception as e:
                self.logger.error(f"ç…§ç‰‡ {photo_id}: æ ‡ç­¾å’Œåˆ†ç±»ç”Ÿæˆå¤±è´¥: {str(e)}")
                import traceback
                self.logger.error(f"ç…§ç‰‡ {photo_id}: è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
                raise

            # æäº¤æ‰€æœ‰æ ‡ç­¾å’Œåˆ†ç±»çš„æ•°æ®åº“æ“ä½œ
            db.commit()

            # è¿”å›ç»¼åˆç»“æœï¼ˆç§»é™¤æ„ŸçŸ¥å“ˆå¸Œï¼Œå› ä¸ºå·²åœ¨å¯¼å…¥æ—¶è®¡ç®—ï¼‰
            return {
                "photo_id": photo_id,
                "content_analysis": content_result,
                "quality_analysis": quality_result,
                "perceptual_hash_calculated_at_import": True,  # æ ‡è®°å“ˆå¸Œåœ¨å¯¼å…¥æ—¶å·²è®¡ç®—
                "analyzed_at": datetime.now().isoformat()
            }

        except Exception as e:
            db.rollback()
            self.logger.error(f"ä¿å­˜åˆ†æç»“æœå¤±è´¥ {photo_id}: {str(e)}")
            raise Exception(f"ä¿å­˜åˆ†æç»“æœå¤±è´¥: {str(e)}")

    def _save_error_result(self, photo_id: int, error_info: Dict[str, Any], db, original_status: str = None, analysis_type: str = None) -> None:
        """
        å¤„ç†åˆ†æå¤±è´¥ï¼Œåªæ¢å¤çŠ¶æ€ï¼Œä¸è®°å½•é”™è¯¯ä¿¡æ¯
        
        Args:
            photo_id: ç…§ç‰‡ID
            error_info: é”™è¯¯ä¿¡æ¯å­—å…¸ï¼ˆä¿ç•™å‚æ•°å…¼å®¹æ€§ï¼Œä½†ä¸ä½¿ç”¨ï¼‰
            db: æ•°æ®åº“ä¼šè¯
            original_status: åŸå§‹çŠ¶æ€ï¼Œç”¨äºå¤±è´¥æ—¶æ¢å¤
            analysis_type: åˆ†æç±»å‹ï¼ˆä¿ç•™å‚æ•°å…¼å®¹æ€§ï¼Œä½†ä¸ä½¿ç”¨ï¼‰
        """
        try:
            self.logger.info(f"å¤„ç†ç…§ç‰‡ {photo_id} åˆ†æå¤±è´¥ï¼Œæ¢å¤çŠ¶æ€")
            
            # ä¸æ›´æ–°PhotoAnalysisè¡¨ï¼Œä¿æŒåŸæœ‰æ•°æ®å®Œæ•´æ€§
            # åªå¤„ç†çŠ¶æ€æ¢å¤
            photo = db.query(Photo).filter(Photo.id == photo_id).first()
            if photo:
                if original_status:
                    # æœ‰åŸå§‹çŠ¶æ€ï¼Œç›´æ¥æ¢å¤
                    photo.status = original_status
                    photo.updated_at = datetime.now()
                    self.logger.info(f"ç…§ç‰‡ {photo_id} çŠ¶æ€å·²æ¢å¤ä¸º: {original_status}")
                else:
                    # æ²¡æœ‰åŸå§‹çŠ¶æ€ï¼Œæ ¹æ®åˆ†æç±»å‹æ™ºèƒ½æ¢å¤
                    current_status = photo.status
                    if analysis_type == 'quality':
                        # åŸºç¡€åˆ†æå¤±è´¥ï¼Œå¦‚æœå½“å‰æ˜¯analyzingï¼Œæ¢å¤ä¸ºimported
                        if current_status == 'analyzing':
                            photo.status = 'imported'
                            photo.updated_at = datetime.now()
                            self.logger.info(f"ç…§ç‰‡ {photo_id} åŸºç¡€åˆ†æå¤±è´¥ï¼ŒçŠ¶æ€ä» {current_status} æ¢å¤ä¸º: imported")
                    elif analysis_type == 'content':
                        # AIåˆ†æå¤±è´¥ï¼Œå¦‚æœå½“å‰æ˜¯analyzingï¼Œæ¢å¤ä¸ºimported
                        if current_status == 'analyzing':
                            photo.status = 'imported'
                            photo.updated_at = datetime.now()
                            self.logger.info(f"ç…§ç‰‡ {photo_id} AIåˆ†æå¤±è´¥ï¼ŒçŠ¶æ€ä» {current_status} æ¢å¤ä¸º: imported")

            db.commit()
            self.logger.info(f"ç…§ç‰‡ {photo_id} çŠ¶æ€æ¢å¤å®Œæˆï¼Œä¿æŒåŸæœ‰åˆ†ææ•°æ®å®Œæ•´æ€§")

        except Exception as e:
            db.rollback()
            self.logger.error(f"æ¢å¤ç…§ç‰‡çŠ¶æ€å¤±è´¥ {photo_id}: {str(e)}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œé¿å…å½±å“ä¸»æµç¨‹

    async def batch_analyze_photos(self, photo_ids: List[int], db: Session = None) -> Dict[str, Any]:
        """
        æ‰¹é‡åˆ†æç…§ç‰‡ - å¤‡ç”¨æ¥å£ï¼Œä¸»è¦ç”¨äºç›´æ¥è°ƒç”¨åœºæ™¯
        æ³¨æ„ï¼šæ­¤å‡½æ•°ç°åœ¨ä¸»è¦ç”¨äºå…¼å®¹æ€§ï¼Œå®é™…å¹¶å‘å¤„ç†åœ¨APIå±‚

        Args:
            photo_ids: ç…§ç‰‡IDåˆ—è¡¨
            db: æ•°æ®åº“ä¼šè¯

        Returns:
            æ‰¹é‡åˆ†æç»“æœ
        """
        try:
            self.logger.info(f"å¼€å§‹æ‰¹é‡åˆ†æ {len(photo_ids)} å¼ ç…§ç‰‡ï¼ˆå¤‡ç”¨æ¥å£ï¼‰")
            
            # éªŒè¯è¾“å…¥å‚æ•°
            if not photo_ids:
                self.logger.warning("ç…§ç‰‡IDåˆ—è¡¨ä¸ºç©º")
                return {
                    "total_photos": 0,
                    "successful_analyses": 0,
                    "failed_analyses": 0,
                    "results": [],
                    "errors": [],
                    "completed_at": datetime.now().isoformat()
                }

            results = {
                "total_photos": len(photo_ids),
                "successful_analyses": 0,
                "failed_analyses": 0,
                "results": [],
                "errors": []
            }

            # ğŸ”¥ ç®€åŒ–ï¼šç§»é™¤é‡å¤çš„å¹¶å‘é€»è¾‘ï¼Œä¸“æ³¨äºå•å¼ ç…§ç‰‡åˆ†æ
            for photo_id in photo_ids:
                try:
                    result = await self.analyze_photo(photo_id, db)
                    results["successful_analyses"] += 1
                    results["results"].append({
                        "photo_id": photo_id,
                        "status": "success",
                        "result": result
                    })
                except Exception as e:
                    self.logger.error(f"ç…§ç‰‡ {photo_id} åˆ†æå¤±è´¥: {str(e)}")
                    results["failed_analyses"] += 1
                    results["errors"].append({
                        "photo_id": photo_id,
                        "status": "error",
                        "error": str(e)
                    })

            results["completed_at"] = datetime.now().isoformat()

            self.logger.info(f"æ‰¹é‡åˆ†æå®Œæˆ: {results['successful_analyses']}/{results['total_photos']} æˆåŠŸ")
            return results

        except Exception as e:
            self.logger.error(f"æ‰¹é‡åˆ†æå¤±è´¥: {str(e)}")
            import traceback
            self.logger.error(f"æ‰¹é‡åˆ†æè¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            raise Exception(f"æ‰¹é‡åˆ†æå¤±è´¥: {str(e)}")

    def get_analysis_status(self, photo_id: int, db_session) -> Dict[str, Any]:
        """
        è·å–ç…§ç‰‡åˆ†æçŠ¶æ€

        Args:
            photo_id: ç…§ç‰‡ID
            db_session: æ•°æ®åº“ä¼šè¯

        Returns:
            åˆ†æçŠ¶æ€ä¿¡æ¯
        """
        try:
            # æŸ¥è¯¢å†…å®¹åˆ†æ
            content_analysis = db_session.query(PhotoAnalysis).filter(
                PhotoAnalysis.photo_id == photo_id,
                PhotoAnalysis.analysis_type == "content"
            ).first()

            # æŸ¥è¯¢è´¨é‡åˆ†æ
            quality_analysis = db_session.query(PhotoQuality).filter(
                PhotoQuality.photo_id == photo_id
            ).first()

            # æŸ¥è¯¢ç…§ç‰‡ï¼ˆæ„ŸçŸ¥å“ˆå¸Œå·²åœ¨å¯¼å…¥æ—¶è®¾ç½®ï¼‰
            photo = db_session.query(Photo).filter(Photo.id == photo_id).first()
            has_perceptual_hash = photo.perceptual_hash is not None if photo else False

            status = {
                "photo_id": photo_id,
                "has_content_analysis": content_analysis is not None,
                "has_quality_analysis": quality_analysis is not None,
                "has_perceptual_hash": has_perceptual_hash,  # ä»…ç”¨äºçŠ¶æ€æ£€æŸ¥ï¼Œä¸å†åœ¨åˆ†ææ—¶è®¡ç®—
                "analysis_complete": (
                    content_analysis is not None and
                    quality_analysis is not None
                    # ä¸å†è¦æ±‚å¿…é¡»æœ‰æ„ŸçŸ¥å“ˆå¸Œï¼Œå› ä¸ºå¯¼å…¥æ—¶å·²è®¡ç®—
                )
            }

            if content_analysis:
                status["content_analysis_time"] = content_analysis.created_at.isoformat() if content_analysis.created_at else None
                status["content_confidence"] = content_analysis.confidence_score

            if quality_analysis:
                status["quality_analysis_time"] = quality_analysis.created_at.isoformat() if quality_analysis.created_at else None
                status["quality_score"] = quality_analysis.quality_score

            return status

        except Exception as e:
            self.logger.error(f"è·å–åˆ†æçŠ¶æ€å¤±è´¥ {photo_id}: {str(e)}")
            raise Exception(f"è·å–åˆ†æçŠ¶æ€å¤±è´¥: {str(e)}")

    def get_analysis_results(self, photo_id: int, db_session) -> Dict[str, Any]:
        """
        è·å–ç…§ç‰‡åˆ†æç»“æœ

        Args:
            photo_id: ç…§ç‰‡ID
            db_session: æ•°æ®åº“ä¼šè¯

        Returns:
            å®Œæ•´çš„åˆ†æç»“æœ
        """
        try:
            # æŸ¥è¯¢å†…å®¹åˆ†æ
            content_analysis = db_session.query(PhotoAnalysis).filter(
                PhotoAnalysis.photo_id == photo_id,
                PhotoAnalysis.analysis_type == "content"
            ).first()

            # æŸ¥è¯¢è´¨é‡åˆ†æ
            quality_analysis = db_session.query(PhotoQuality).filter(
                PhotoQuality.photo_id == photo_id
            ).first()

            # æŸ¥è¯¢ç…§ç‰‡åŸºæœ¬ä¿¡æ¯
            photo = db_session.query(Photo).filter(Photo.id == photo_id).first()

            result = {
                "photo_id": photo_id,
                "filename": photo.filename if photo else None,
                "content_analysis": content_analysis.analysis_result if content_analysis else None,
                "quality_analysis": {
                    "quality_score": quality_analysis.quality_score if quality_analysis else None,
                    "sharpness_score": quality_analysis.sharpness_score if quality_analysis else None,
                    "brightness_score": quality_analysis.brightness_score if quality_analysis else None,
                    "contrast_score": quality_analysis.contrast_score if quality_analysis else None,
                    "color_score": quality_analysis.color_score if quality_analysis else None,
                    "composition_score": quality_analysis.composition_score if quality_analysis else None,
                    "quality_level": quality_analysis.quality_level if quality_analysis else None,
                    "technical_issues": quality_analysis.technical_issues if quality_analysis else None
                } if quality_analysis else None,
                "perceptual_hash": photo.perceptual_hash if photo else None,  # ä¿ç•™ä»¥ä¿æŒAPIå…¼å®¹æ€§
                "note": "æ„ŸçŸ¥å“ˆå¸Œåœ¨å¯¼å…¥æ—¶å·²è®¡ç®—ï¼Œæ­¤å¤„ä»…ä¸ºæ˜¾ç¤º"
            }

            return result

        except Exception as e:
            self.logger.error(f"è·å–åˆ†æç»“æœå¤±è´¥ {photo_id}: {str(e)}")
            raise Exception(f"è·å–åˆ†æç»“æœå¤±è´¥: {str(e)}")

    async def generate_photo_caption(self, photo_id: int, style: str = "natural") -> str:
        """
        ä¸ºç…§ç‰‡ç”Ÿæˆæ ‡é¢˜

        Args:
            photo_id: ç…§ç‰‡ID
            style: ç”Ÿæˆé£æ ¼

        Returns:
            ç”Ÿæˆçš„æ ‡é¢˜
        """
        try:
            db = next(get_db())
            photo = db.query(Photo).filter(Photo.id == photo_id).first()

            if not photo or not photo.original_path:
                raise Exception("ç…§ç‰‡ä¸å­˜åœ¨æˆ–æ–‡ä»¶è·¯å¾„æ— æ•ˆ")

            # æ„å»ºå®Œæ•´çš„æ–‡ä»¶è·¯å¾„
            storage_base = Path(settings.storage.base_path)
            full_path = storage_base / photo.original_path
            
            if not full_path.exists():
                raise Exception(f"ç…§ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {full_path}")

            # ä½¿ç”¨DashScopeç”Ÿæˆæ ‡é¢˜
            caption = await asyncio.get_event_loop().run_in_executor(
                self.executor,
                self.dashscope_service.generate_photo_caption,
                str(full_path),
                style
            )

            return caption

        except Exception as e:
            self.logger.error(f"ç”Ÿæˆç…§ç‰‡æ ‡é¢˜å¤±è´¥ {photo_id}: {str(e)}")
            raise Exception(f"ç”Ÿæˆæ ‡é¢˜å¤±è´¥: {str(e)}")

    def detect_duplicates_for_photo(self, photo_id: int, db_session) -> Dict[str, Any]:
        """
        æ£€æµ‹æŒ‡å®šç…§ç‰‡çš„é‡å¤é¡¹

        Args:
            photo_id: ç…§ç‰‡ID
            db_session: æ•°æ®åº“ä¼šè¯

        Returns:
            é‡å¤æ£€æµ‹ç»“æœ
        """
        return self.duplicate_service.detect_duplicates_for_photo(photo_id, db_session)
