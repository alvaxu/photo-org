"""
照片导入API

提供照片文件导入、文件夹扫描、元数据提取等功能的API接口

作者：AI助手
创建日期：2025年9月9日
"""

import os
import shutil
import tempfile
import asyncio
from pathlib import Path
from typing import List, Optional, Tuple
from datetime import datetime
from fastapi import APIRouter, UploadFile, File, Form, HTTPException, BackgroundTasks, Depends
from sqlalchemy.orm import Session
from fastapi.responses import JSONResponse

from app.core.config import settings
from app.db.session import get_db
from app.models.photo import Photo
from app.services.import_service import ImportService
from app.services.photo_service import PhotoService

router = APIRouter()

# 任务状态存储（生产环境建议使用Redis）
task_status = {}




@router.post("/upload")
async def upload_photos(
    files: List[UploadFile] = File(...),
    background_tasks: BackgroundTasks = None,
    db: Session = Depends(get_db)
):
    """
    上传照片文件

    :param files: 上传的文件列表
    :param background_tasks: 后台任务
    :param db: 数据库会话
    :return: 上传结果
    """
    if not files:
        raise HTTPException(status_code=400, detail="未选择文件")

    if len(files) > settings.import_config.max_upload_files:  # 限制单次上传数量
        raise HTTPException(status_code=400, detail=f"单次最多上传{settings.import_config.max_upload_files}个文件")

    try:
        # 统一使用后台任务处理
        import uuid
        task_id = str(uuid.uuid4())
        background_tasks.add_task(process_photos_batch_with_status_from_upload, files, db, task_id)

        return JSONResponse(
            status_code=202,
            content={
                "success": True,
                "message": f"已提交{len(files)}个文件进行后台处理",
                "data": {
                    "task_id": task_id,
                    "total_files": len(files),
                    "status": "processing"
                }
            }
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"文件上传失败: {str(e)}")


@router.post("/process-single")
async def process_single_file(
    file_path: str,
    db: Session = Depends(get_db)
):
    """
    处理单个照片文件

    :param file_path: 文件路径
    :param db: 数据库会话
    """
    try:
        import_service = ImportService()
        photo_service = PhotoService()

        # 处理照片
        success, message, photo_data, duplicate_info = import_service.process_single_photo(file_path, db_session=db)

        if success and photo_data:
            # 保存到数据库
            photo = photo_service.create_photo(db, photo_data)

            return JSONResponse(
                status_code=200,
                content={
                    "success": True,
                    "message": "照片处理成功",
                    "data": {
                        "photo_id": photo.id,
                        "filename": photo.filename,
                        "file_size": photo.file_size,
                        "width": photo.width,
                        "height": photo.height
                    }
                }
            )
        elif duplicate_info:
            # 处理重复文件 - 改为统一响应格式，不抛出异常
            duplicate_type = duplicate_info.get('duplicate_type', 'unknown')
            message = duplicate_info.get('message', '文件重复')
            
            # 根据重复类型生成更详细的提示
            if duplicate_type == 'full_duplicate_completed':
                status_text = f"文件已存在且已完成智能处理"
            elif duplicate_type == 'full_duplicate_incomplete':
                status_text = f"文件已存在但未完成智能处理 - 将重新处理"
            elif duplicate_type == 'physical_only':
                status_text = f"文件已存在（物理重复）"
            elif duplicate_type == 'orphan_cleaned':
                status_text = f"孤儿记录已清理，继续处理"
            else:
                status_text = message
            
            # 返回统一的响应格式，包含重复信息
            return JSONResponse(
                status_code=200,
                content={
                    "success": False,
                    "message": "文件重复",
                    "data": {
                        "duplicate_type": duplicate_type,
                        "duplicate_message": status_text,
                        "filename": Path(file_path).name
                    }
                }
            )
        else:
            # 其他错误情况也改为统一响应格式
            return JSONResponse(
                status_code=200,
                content={
                    "success": False,
                    "message": "处理失败",
                    "data": {
                        "error_message": message,
                        "filename": Path(file_path).name
                    }
                }
            )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"照片处理失败: {str(e)}")


@router.get("/supported-formats")
async def get_supported_formats():
    """
    获取支持的文件格式
    """
    import_service = ImportService()

    return JSONResponse(
        status_code=200,
        content={
            "success": True,
            "data": {
                "formats": import_service.SUPPORTED_FORMATS,
                "mimetypes": import_service.SUPPORTED_MIMETYPES,
                "max_file_size": settings.system.max_file_size
            }
        }
    )


@router.get("/import-status")
async def get_import_status():
    """
    获取导入状态（预留接口，后续实现）
    """
    return JSONResponse(
        status_code=200,
        content={
            "success": True,
            "message": "导入服务正常运行",
            "data": {
                "status": "idle",
                "processed_today": 0,
                "queue_length": 0
            }
        }
    )






@router.get("/scan-status/{task_id}")
async def get_scan_status(task_id: str):
    """
    获取扫描任务状态

    :param task_id: 任务ID
    """
    print(f"查询任务状态: {task_id}")
    # print(f"当前任务状态: {task_status}")

    if task_id not in task_status:
        print(f"任务 {task_id} 不存在")
        raise HTTPException(status_code=404, detail="任务不存在")

    # print(f"任务 {task_id} 状态: {task_status[task_id]}")
    return task_status[task_id]


@router.post("/batch-status")
async def get_batch_status(task_ids: List[str]):
    """
    获取多个批次任务的聚合状态

    :param task_ids: 任务ID列表
    :return: 批次聚合状态
    """
    print(f"查询批次状态，任务数量: {len(task_ids)}")

    if not task_ids:
        raise HTTPException(status_code=400, detail="任务ID列表不能为空")

    batch_results = []
    total_files = 0
    total_processed = 0
    total_imported = 0
    total_skipped = 0
    total_failed = 0
    failed_files = []
    completed_tasks = 0

    for task_id in task_ids:
        if task_id in task_status:
            task_data = task_status[task_id]
            batch_results.append({
                "task_id": task_id,
                "status": task_data.get("status", "unknown"),
                "total_files": task_data.get("total_files", 0),
                "processed_files": task_data.get("processed_files", 0),
                "imported_count": task_data.get("imported_count", 0),
                "skipped_count": task_data.get("skipped_count", 0),
                "failed_count": task_data.get("failed_count", 0),
                "failed_files": task_data.get("failed_files", []),
                "progress_percentage": task_data.get("progress_percentage", 0)
            })

            # 累积统计
            total_files += task_data.get("total_files", 0)
            total_processed += task_data.get("processed_files", 0)
            total_imported += task_data.get("imported_count", 0)
            total_skipped += task_data.get("skipped_count", 0)
            total_failed += task_data.get("failed_count", 0)
            failed_files.extend(task_data.get("failed_files", []))

            if task_data.get("status") == "completed":
                completed_tasks += 1
        else:
            # 任务不存在，视为失败
            batch_results.append({
                "task_id": task_id,
                "status": "not_found",
                "error": "任务不存在"
            })

    # 计算总体状态
    overall_status = "completed" if completed_tasks == len(task_ids) else "processing"
    overall_progress = (completed_tasks / len(task_ids) * 100) if task_ids else 0

    result = {
        "overall_status": overall_status,
        "overall_progress_percentage": round(overall_progress, 1),
        "completed_tasks": completed_tasks,
        "total_tasks": len(task_ids),
        "total_files": total_files,
        "total_processed_files": total_processed,
        "total_imported_count": total_imported,
        "total_skipped_count": total_skipped,
        "total_failed_count": total_failed,
        "failed_files": failed_files,
        "task_details": batch_results
    }

    print(f"批次聚合状态: {completed_tasks}/{len(task_ids)} 完成，总体进度: {overall_progress}%")
    return result


async def process_photos_batch_with_status_from_upload(files: List[UploadFile], db, task_id: str):
    """
    带状态跟踪的处理上传文件 - 使用asyncio并发处理
    
    :param files: 上传的文件列表
    :param db: 数据库会话
    :param task_id: 任务ID
    """
    try:
        # 初始化任务状态
        task_status[task_id] = {
            "status": "processing",
            "total_files": len(files),
            "processed_files": 0,
            "imported_count": 0,
            "skipped_count": 0,
            "failed_count": 0,
            "failed_files": [],
            "progress_percentage": 0,
            "start_time": datetime.now().isoformat(),
            "end_time": None,
            "error": None
        }
        
        import_service = ImportService()
        photo_service = PhotoService()
        
        # 限制并发数量，避免资源耗尽
        semaphore = asyncio.Semaphore(3)  # 最多同时处理3个文件
        
        async def process_single_file_with_semaphore(file: UploadFile, file_index: int):
            """使用信号量控制并发处理单个文件"""
            async with semaphore:
                try:
                    # 验证文件类型
                    file_ext = Path(file.filename).suffix.lower()
                    
                    # 特殊处理HEIC格式
                    if file_ext in ['.heic', '.heif']:
                        # HEIC格式的content_type可能为空，需要特殊处理
                        pass
                    elif not file.content_type or not file.content_type.startswith('image/'):
                        return {
                            "file_index": file_index,
                            "filename": file.filename,
                            "status": "failed",
                            "message": "不支持的文件类型"
                        }

                    # 保存临时文件
                    with tempfile.NamedTemporaryFile(delete=False, suffix=Path(file.filename).suffix) as temp_file:
                        shutil.copyfileobj(file.file, temp_file)
                        temp_path = temp_file.name

                    try:
                        # 处理单个照片
                        success, message, photo_data, duplicate_info = import_service.process_single_photo(
                            temp_path, move_file=False, db_session=db
                        )

                        if success and photo_data:
                            # 保存到数据库
                            photo = photo_service.create_photo(db, photo_data)
                            if photo:
                                print(f"成功导入: {file.filename}")
                                return {
                                    "file_index": file_index,
                                    "filename": file.filename,
                                    "status": "imported",
                                    "message": "导入成功"
                                }
                            else:
                                return {
                                    "file_index": file_index,
                                    "filename": file.filename,
                                    "status": "failed",
                                    "message": "数据库保存失败"
                                }
                        elif duplicate_info:
                            # 处理重复文件 - 使用完整的重复检测逻辑
                            duplicate_type = duplicate_info.get('duplicate_type', 'unknown')
                            message = duplicate_info.get('message', '文件重复')
                            
                            # 根据重复类型生成更详细的提示
                            if duplicate_type == 'full_duplicate_completed':
                                status_text = f"文件已存在且已完成智能处理"
                                return {
                                    "file_index": file_index,
                                    "filename": file.filename,
                                    "status": "skipped",
                                    "message": status_text
                                }
                            elif duplicate_type == 'full_duplicate_incomplete':
                                status_text = f"文件已存在但未完成智能处理 - 将重新处理"
                                return {
                                    "file_index": file_index,
                                    "filename": file.filename,
                                    "status": "skipped",
                                    "message": status_text
                                }
                            elif duplicate_type == 'physical_only':
                                status_text = f"文件已存在（物理重复）"
                                return {
                                    "file_index": file_index,
                                    "filename": file.filename,
                                    "status": "imported",
                                    "message": status_text
                                }
                            elif duplicate_type == 'orphan_cleaned':
                                status_text = f"孤儿记录已清理，继续处理"
                                return {
                                    "file_index": file_index,
                                    "filename": file.filename,
                                    "status": "imported",
                                    "message": status_text
                                }
                            else:
                                return {
                                    "file_index": file_index,
                                    "filename": file.filename,
                                    "status": "failed",
                                    "message": message
                                }
                        else:
                            return {
                                "file_index": file_index,
                                "filename": file.filename,
                                "status": "failed",
                                "message": message
                            }

                    finally:
                        # 清理临时文件
                        if os.path.exists(temp_path):
                            os.unlink(temp_path)

                except Exception as e:
                    return {
                        "file_index": file_index,
                        "filename": file.filename,
                        "status": "failed",
                        "message": f"处理异常 - {str(e)}"
                    }
        
        # 并发执行所有文件处理任务
        try:
            tasks = [process_single_file_with_semaphore(file, i) for i, file in enumerate(files)]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # 统计结果
            imported_count = 0
            skipped_count = 0
            failed_count = 0
            failed_files = []
            
            for result in results:
                if isinstance(result, Exception):
                    failed_count += 1
                    failed_files.append(f"处理异常: {str(result)}")
                    continue
                    
                if result["status"] == "imported":
                    imported_count += 1
                elif result["status"] == "skipped":
                    skipped_count += 1
                elif result["status"] == "failed":
                    failed_count += 1
                    failed_files.append(f"{result['filename']}: {result['message']}")
            
            # 提交事务
            db.commit()
            
            # 更新最终状态
            task_status[task_id].update({
                "status": "completed",
                "end_time": datetime.now().isoformat(),
                "processed_files": len(files),
                "imported_count": imported_count,
                "skipped_count": skipped_count,
                "failed_count": failed_count,
                "failed_files": failed_files,
                "progress_percentage": 100
            })
            
            print(f"并发处理完成: 导入{imported_count}个，跳过{skipped_count}个，失败{failed_count}个")

        except Exception as e:
            # 回滚事务
            db.rollback()
            task_status[task_id].update({
                "status": "failed",
                "end_time": datetime.now().isoformat(),
                "error": str(e)
            })
            print(f"并发处理失败: {str(e)}")

    except Exception as e:
        # 处理整个函数级别的异常
        task_status[task_id] = {
            "status": "failed",
            "error": str(e),
            "end_time": datetime.now().isoformat()
        }
        print(f"任务初始化失败: {str(e)}")
