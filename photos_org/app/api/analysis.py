"""
å®¶åº­ç‰ˆæ™ºèƒ½ç…§ç‰‡ç³»ç»Ÿ - æ™ºèƒ½åˆ†æAPI
"""
import asyncio
from datetime import datetime
from typing import List, Optional, Dict, Any
from fastapi import APIRouter, Depends, HTTPException, Query, BackgroundTasks
from sqlalchemy.orm import Session
from pydantic import BaseModel, Field

from app.core.config import settings
from app.core.logging import get_logger
from app.db.session import get_db
from app.services.analysis_service import AnalysisService
from app.models.photo import Photo, PhotoAnalysis

logger = get_logger(__name__)

router = APIRouter()

# å…¨å±€åˆ†æä»»åŠ¡çŠ¶æ€è·Ÿè¸ªï¼ˆç±»ä¼¼å¯¼å…¥æ¨¡å—çš„task_statusï¼‰
analysis_task_status = {}

# ä»»åŠ¡çŠ¶æ€æ¸…ç†é…ç½®
TASK_STATUS_CLEANUP_HOURS = 1  # ä»»åŠ¡å®Œæˆå1å°æ—¶æ¸…ç†çŠ¶æ€


# è¯·æ±‚/å“åº”æ¨¡å‹
class AnalysisRequest(BaseModel):
    """åˆ†æè¯·æ±‚"""
    photo_ids: List[int] = Field(..., description="è¦åˆ†æçš„ç…§ç‰‡IDåˆ—è¡¨")
    analysis_types: List[str] = Field(["content"], description="åˆ†æç±»å‹")
    force_reprocess: bool = Field(False, description="æ˜¯å¦å¼ºåˆ¶é‡æ–°å¤„ç†å·²åˆ†æçš„ç…§ç‰‡")


class AnalysisResponse(BaseModel):
    """åˆ†æå“åº”"""
    photo_id: int = Field(..., description="ç…§ç‰‡ID")
    status: str = Field(..., description="åˆ†æçŠ¶æ€")
    content_analysis: Optional[Dict[str, Any]] = Field(None, description="å†…å®¹åˆ†æç»“æœ")
    perceptual_hash: Optional[str] = Field(None, description="æ„ŸçŸ¥å“ˆå¸Œ")
    analyzed_at: str = Field(..., description="åˆ†ææ—¶é—´")


class BatchAnalysisResponse(BaseModel):
    """æ‰¹é‡åˆ†æå“åº”"""
    total_photos: int = Field(..., description="æ€»ç…§ç‰‡æ•°")
    successful_analyses: int = Field(..., description="æˆåŠŸåˆ†ææ•°")
    failed_analyses: int = Field(..., description="å¤±è´¥åˆ†ææ•°")
    results: List[Dict[str, Any]] = Field(default_factory=list, description="åˆ†æç»“æœåˆ—è¡¨")
    errors: List[Dict[str, Any]] = Field(default_factory=list, description="é”™è¯¯åˆ—è¡¨")
    completed_at: str = Field(..., description="å®Œæˆæ—¶é—´")


class CaptionRequest(BaseModel):
    """æ ‡é¢˜ç”Ÿæˆè¯·æ±‚"""
    photo_id: int = Field(..., description="ç…§ç‰‡ID")
    style: str = Field("natural", description="ç”Ÿæˆé£æ ¼", pattern="^(natural|creative|poetic)$")


class CaptionResponse(BaseModel):
    """æ ‡é¢˜ç”Ÿæˆå“åº”"""
    photo_id: int = Field(..., description="ç…§ç‰‡ID")
    caption: str = Field(..., description="ç”Ÿæˆçš„æ ‡é¢˜")
    style: str = Field(..., description="ç”Ÿæˆé£æ ¼")


@router.post("/analyze", response_model=AnalysisResponse)
async def analyze_photo(
    photo_id: int,
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db)
):
    """
    åˆ†æå•å¼ ç…§ç‰‡

    - **photo_id**: è¦åˆ†æçš„ç…§ç‰‡ID
    """
    try:
        # éªŒè¯ç…§ç‰‡å­˜åœ¨
        photo = db.query(Photo).filter(Photo.id == photo_id).first()
        if not photo:
            raise HTTPException(status_code=404, detail="ç…§ç‰‡ä¸å­˜åœ¨")

        # åˆ›å»ºåˆ†ææœåŠ¡
        analysis_service = AnalysisService()

        # æ·»åŠ åå°åˆ†æä»»åŠ¡
        background_tasks.add_task(perform_analysis, photo_id)

        return AnalysisResponse(
            photo_id=photo_id,
            status="analyzing",
            analyzed_at=datetime.now().isoformat(),
            content_analysis=None,
            perceptual_hash=None
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å¯åŠ¨ç…§ç‰‡åˆ†æå¤±è´¥ {photo_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å¯åŠ¨åˆ†æå¤±è´¥: {str(e)}")


@router.post("/batch-analyze", response_model=BatchAnalysisResponse)
async def batch_analyze_photos(
    request: AnalysisRequest,
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db)
):
    """
    æ‰¹é‡åˆ†æç…§ç‰‡

    - **photo_ids**: è¦åˆ†æçš„ç…§ç‰‡IDåˆ—è¡¨
    - **analysis_types**: åˆ†æç±»å‹åˆ—è¡¨
    """
    try:
        # éªŒè¯ç…§ç‰‡å­˜åœ¨å¹¶è¿‡æ»¤çŠ¶æ€
        existing_photos = db.query(Photo).filter(Photo.id.in_(request.photo_ids)).all()
        existing_ids = {photo.id for photo in existing_photos}

        if len(existing_ids) != len(request.photo_ids):
            missing_ids = set(request.photo_ids) - existing_ids
            raise HTTPException(status_code=404, detail=f"ç…§ç‰‡ä¸å­˜åœ¨: {list(missing_ids)}")

        # æ ¹æ®force_reprocesså‚æ•°å†³å®šå¤„ç†å“ªäº›ç…§ç‰‡
        if request.force_reprocess:
            # å¼ºåˆ¶é‡æ–°å¤„ç†æ‰€æœ‰ç…§ç‰‡
            photos_to_process = existing_photos
            logger.info("å¯ç”¨å¼ºåˆ¶é‡æ–°å¤„ç†æ¨¡å¼ï¼Œå°†å¤„ç†æ‰€æœ‰é€‰ä¸­çš„ç…§ç‰‡")
        else:
            # åªå¤„ç†importedå’ŒerrorçŠ¶æ€çš„ç…§ç‰‡
            photos_to_process = [photo for photo in existing_photos if photo.status in ['imported', 'error']]
            logger.info("ä½¿ç”¨é»˜è®¤æ¨¡å¼ï¼Œåªå¤„ç†æœªåˆ†æçš„ç…§ç‰‡")
        
        logger.info(f"æ‰¹é‡åˆ†æè¯·æ±‚: æ€»ç…§ç‰‡æ•°={len(existing_photos)}, éœ€è¦å¤„ç†çš„ç…§ç‰‡æ•°={len(photos_to_process)}")
        for photo in existing_photos:
            logger.info(f"ç…§ç‰‡ID={photo.id}, çŠ¶æ€={photo.status}")
        
        if not photos_to_process:
            logger.info("æ²¡æœ‰éœ€è¦å¤„ç†çš„ç…§ç‰‡ï¼Œè¿”å›ç©ºç»“æœ")
            return BatchAnalysisResponse(
                total_photos=0,
                successful_analyses=0,
                failed_analyses=0,
                results=[],
                errors=[],
                completed_at=datetime.now().isoformat(),
                message="æ²¡æœ‰éœ€è¦å¤„ç†çš„ç…§ç‰‡ï¼Œæ‰€æœ‰ç…§ç‰‡éƒ½å·²å®Œæˆåˆ†æ"
            )

        # åˆ›å»ºåˆ†ææœåŠ¡
        analysis_service = AnalysisService()

        # æ·»åŠ åå°æ‰¹é‡åˆ†æä»»åŠ¡
        photo_ids_to_process = [photo.id for photo in photos_to_process]
        background_tasks.add_task(perform_batch_analysis, photo_ids_to_process)

        return BatchAnalysisResponse(
            total_photos=len(photo_ids_to_process),
            successful_analyses=0,
            failed_analyses=0,
            results=[],
            errors=[],
            completed_at=datetime.now().isoformat()
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å¯åŠ¨æ‰¹é‡åˆ†æå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å¯åŠ¨æ‰¹é‡åˆ†æå¤±è´¥: {str(e)}")


@router.get("/status/{photo_id}")
async def get_analysis_status(photo_id: int, db: Session = Depends(get_db)):
    """
    è·å–ç…§ç‰‡åˆ†æçŠ¶æ€

    - **photo_id**: ç…§ç‰‡ID
    """
    try:
        # éªŒè¯ç…§ç‰‡å­˜åœ¨
        photo = db.query(Photo).filter(Photo.id == photo_id).first()
        if not photo:
            raise HTTPException(status_code=404, detail="ç…§ç‰‡ä¸å­˜åœ¨")

        analysis_service = AnalysisService()
        status = analysis_service.get_analysis_status(photo_id, db)

        return status

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–åˆ†æçŠ¶æ€å¤±è´¥ {photo_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–åˆ†æçŠ¶æ€å¤±è´¥: {str(e)}")


@router.get("/results/{photo_id}")
async def get_analysis_results(photo_id: int, db: Session = Depends(get_db)):
    """
    è·å–ç…§ç‰‡åˆ†æç»“æœ

    - **photo_id**: ç…§ç‰‡ID
    """
    try:
        # éªŒè¯ç…§ç‰‡å­˜åœ¨
        photo = db.query(Photo).filter(Photo.id == photo_id).first()
        if not photo:
            raise HTTPException(status_code=404, detail="ç…§ç‰‡ä¸å­˜åœ¨")

        analysis_service = AnalysisService()
        results = analysis_service.get_analysis_results(photo_id, db)

        return results

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–åˆ†æç»“æœå¤±è´¥ {photo_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–åˆ†æç»“æœå¤±è´¥: {str(e)}")


@router.post("/caption", response_model=CaptionResponse)
async def generate_caption(request: CaptionRequest):
    """
    ä¸ºç…§ç‰‡ç”Ÿæˆæ ‡é¢˜

    - **photo_id**: ç…§ç‰‡ID
    - **style**: ç”Ÿæˆé£æ ¼ (natural/creative/poetic)
    """
    try:
        analysis_service = AnalysisService()
        caption = await analysis_service.generate_photo_caption(request.photo_id, request.style)

        return CaptionResponse(
            photo_id=request.photo_id,
            caption=caption,
            style=request.style
        )

    except Exception as e:
        logger.error(f"ç”Ÿæˆç…§ç‰‡æ ‡é¢˜å¤±è´¥ {request.photo_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆæ ‡é¢˜å¤±è´¥: {str(e)}")


@router.get("/pending-photos")
async def get_pending_photos(db: Session = Depends(get_db)):
    """
    è·å–æ‰€æœ‰å¾…å¤„ç†çš„ç…§ç‰‡IDåˆ—è¡¨

    è¿”å›çŠ¶æ€ä¸º'imported'æˆ–'error'çš„æ‰€æœ‰ç…§ç‰‡IDï¼Œç”¨äºæ™ºèƒ½å¤„ç†
    """
    try:
        # è·å–æ‰€æœ‰çŠ¶æ€ä¸ºimportedæˆ–errorçš„ç…§ç‰‡ID
        pending_photos = db.query(Photo.id).filter(Photo.status.in_(['imported', 'error'])).all()

        photo_ids = [photo.id for photo in pending_photos]

        return {
            "photo_ids": photo_ids,
            "total_count": len(photo_ids),
            "message": f"æ‰¾åˆ° {len(photo_ids)} å¼ å¾…å¤„ç†çš„ç…§ç‰‡"
        }

    except Exception as e:
        logger.error(f"è·å–å¾…å¤„ç†ç…§ç‰‡åˆ—è¡¨å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–å¾…å¤„ç†ç…§ç‰‡åˆ—è¡¨å¤±è´¥: {str(e)}")


@router.get("/queue/status")
async def get_analysis_queue_status(initial_total: int = None, db: Session = Depends(get_db)):
    """
    è·å–åˆ†æé˜Ÿåˆ—çŠ¶æ€
    """
    try:
        # ç»Ÿè®¡å„ç§çŠ¶æ€çš„ç…§ç‰‡æ•°é‡
        all_photos = db.query(Photo).count()
        imported_photos = db.query(Photo).filter(Photo.status == 'imported').count()
        analyzing_photos = db.query(Photo).filter(Photo.status == 'analyzing').count()
        completed_photos = db.query(Photo).filter(Photo.status == 'completed').count()
        quality_completed_photos = db.query(Photo).filter(Photo.status == 'quality_completed').count()
        content_completed_photos = db.query(Photo).filter(Photo.status == 'content_completed').count()
        error_photos = db.query(Photo).filter(Photo.status == 'error').count()
        
        # è®¡ç®—å½“å‰æ‰¹æ¬¡éœ€è¦å¤„ç†çš„ç…§ç‰‡æ•°ï¼ˆimported + errorçŠ¶æ€çš„ç…§ç‰‡ï¼‰
        current_pending_photos = imported_photos + error_photos
        
        # ä½¿ç”¨ä¼ å…¥çš„åˆå§‹æ€»æ•°ä½œä¸ºåˆ†æ¯ï¼Œå¦‚æœæ²¡æœ‰ä¼ å…¥åˆ™ä½¿ç”¨å½“å‰æ€»æ•°
        if initial_total is not None and initial_total > 0:
            total_batch_photos = initial_total
            # åˆ†å­ï¼šåˆå§‹æ€»æ•° - å½“å‰å‰©ä½™çš„å¾…å¤„ç†ç…§ç‰‡æ•°
            batch_completed_photos = total_batch_photos - current_pending_photos
        else:
            # å¦‚æœæ²¡æœ‰ä¼ å…¥åˆå§‹æ€»æ•°ï¼Œä½¿ç”¨å½“å‰æ‰€æœ‰ç…§ç‰‡æ•°ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
            current_processing_or_completed = analyzing_photos + completed_photos
            total_batch_photos = current_pending_photos + current_processing_or_completed
            batch_completed_photos = current_processing_or_completed

        if total_batch_photos > 0:
            progress_percentage = (batch_completed_photos / total_batch_photos * 100)
        else:
            progress_percentage = 100  # å¦‚æœæ²¡æœ‰éœ€è¦å¤„ç†çš„ç…§ç‰‡ï¼Œæ˜¾ç¤º100%
        
        # è®¡ç®—å¤„ç†çŠ¶æ€
        processing_photos = imported_photos + analyzing_photos + error_photos
        is_processing = analyzing_photos > 0
        is_complete = processing_photos == 0 and current_pending_photos > 0
        
        return {
            "all_photos": all_photos,  # æ‰€æœ‰ç…§ç‰‡æ€»æ•°
            "batch_total_photos": total_batch_photos,  # å½“å‰æ‰¹æ¬¡æ€»ç…§ç‰‡æ•°
            "batch_completed_photos": batch_completed_photos,  # å½“å‰æ‰¹æ¬¡å·²å®Œæˆç…§ç‰‡æ•°
            "batch_pending_photos": current_pending_photos,  # å½“å‰æ‰¹æ¬¡å¾…å¤„ç†ç…§ç‰‡æ•°ï¼ˆimported + errorï¼‰
            "imported_photos": imported_photos,
            "analyzing_photos": analyzing_photos,
            "completed_photos": completed_photos,
            "quality_completed_photos": quality_completed_photos,
            "content_completed_photos": content_completed_photos,
            "error_photos": error_photos,
            "processing_photos": processing_photos,
            "progress_percentage": round(progress_percentage, 2),
            "is_processing": is_processing,
            "is_complete": is_complete,
            "last_updated": datetime.now().isoformat()
        }

    except Exception as e:
        logger.error(f"è·å–é˜Ÿåˆ—çŠ¶æ€å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–é˜Ÿåˆ—çŠ¶æ€å¤±è´¥: {str(e)}")


# åå°ä»»åŠ¡å‡½æ•°
async def perform_analysis(photo_id: int):
    """
    æ‰§è¡Œç…§ç‰‡åˆ†æä»»åŠ¡

    Args:
        photo_id: ç…§ç‰‡ID
    """
    try:
        logger.info(f"å¼€å§‹åå°åˆ†æç…§ç‰‡: {photo_id}")
        analysis_service = AnalysisService()
        result = await analysis_service.analyze_photo(photo_id)
        logger.info(f"åå°åˆ†æç…§ç‰‡å®Œæˆ: {photo_id}")

    except Exception as e:
        logger.error(f"åå°åˆ†æç…§ç‰‡å¤±è´¥ {photo_id}: {str(e)}")


async def perform_batch_analysis(photo_ids: List[int]):
    """
    æ‰§è¡Œæ‰¹é‡åˆ†æä»»åŠ¡

    Args:
        photo_ids: ç…§ç‰‡IDåˆ—è¡¨
    """
    try:
        logger.info(f"=== å¼€å§‹åå°æ‰¹é‡åˆ†æç…§ç‰‡: {len(photo_ids)} å¼  ===")
        logger.info(f"ç…§ç‰‡IDåˆ—è¡¨: {photo_ids}")
        
        # éªŒè¯è¾“å…¥å‚æ•°
        if not photo_ids:
            logger.warning("ç…§ç‰‡IDåˆ—è¡¨ä¸ºç©ºï¼Œè·³è¿‡æ‰¹é‡åˆ†æ")
            return
            
        analysis_service = AnalysisService()
        logger.info("AnalysisService åˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºæ–°çš„æ•°æ®åº“ä¼šè¯ç”¨äºåå°ä»»åŠ¡
        logger.info("å¼€å§‹åˆ›å»ºæ•°æ®åº“ä¼šè¯...")
        try:
            db = next(get_db())
            logger.info("æ•°æ®åº“ä¼šè¯åˆ›å»ºæˆåŠŸ")
        except Exception as e:
            logger.error(f"åˆ›å»ºæ•°æ®åº“ä¼šè¯å¤±è´¥: {str(e)}")
            import traceback
            logger.error(f"æ•°æ®åº“ä¼šè¯åˆ›å»ºè¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            raise
            
        try:
            logger.info("å¼€å§‹è°ƒç”¨ batch_analyze_photos...")
            result = await analysis_service.batch_analyze_photos(photo_ids, db)
            logger.info(f"=== åå°æ‰¹é‡åˆ†æå®Œæˆ: {result['successful_analyses']}/{result['total_photos']} ===")
            logger.info(f"æˆåŠŸåˆ†æçš„ç…§ç‰‡: {[r['photo_id'] for r in result.get('results', [])]}")
            if result.get('errors'):
                logger.error(f"åˆ†æå¤±è´¥çš„ç…§ç‰‡: {[e['photo_id'] for e in result['errors']]}")
        except Exception as e:
            logger.error(f"batch_analyze_photos è°ƒç”¨å¤±è´¥: {str(e)}")
            import traceback
            logger.error(f"batch_analyze_photos è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            raise
        finally:
            try:
                db.close()
                logger.info("æ•°æ®åº“ä¼šè¯å·²å…³é—­")
            except Exception as e:
                logger.error(f"å…³é—­æ•°æ®åº“ä¼šè¯å¤±è´¥: {str(e)}")

    except Exception as e:
        logger.error(f"åå°æ‰¹é‡åˆ†æå¤±è´¥: {str(e)}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")


@router.get("/ai-pending-count")
async def get_ai_pending_count(db: Session = Depends(get_db)):
    """
    è·å–éœ€è¦AIåˆ†æçš„ç…§ç‰‡æ•°é‡ç»Ÿè®¡
    AIåˆ†æï¼šåªåŒ…å«å†…å®¹åˆ†æï¼Œä¸åŒ…å«è´¨é‡è¯„ä¼°
    """
    try:
        # ç»Ÿè®¡éœ€è¦AIåˆ†æçš„ç…§ç‰‡ï¼šæ²¡æœ‰AIå†…å®¹åˆ†æç»“æœçš„ç…§ç‰‡
        pending_count = db.query(Photo).filter(
            ~db.query(PhotoAnalysis).filter(
                PhotoAnalysis.photo_id == Photo.id,
                PhotoAnalysis.analysis_type == 'content'
            ).exists()
        ).count()

        return {
            "count": pending_count,
            "message": f"å‘ç° {pending_count} å¼ ç…§ç‰‡éœ€è¦AIåˆ†æ"
        }
    except Exception as e:
        logger.error(f"è·å–AIåˆ†æç»Ÿè®¡å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–AIåˆ†æç»Ÿè®¡å¤±è´¥: {str(e)}")


@router.get("/ai-pending-photos")
async def get_ai_pending_photos(db: Session = Depends(get_db)):
    """
    è·å–éœ€è¦AIåˆ†æçš„ç…§ç‰‡IDåˆ—è¡¨
    è¿”å›æ²¡æœ‰AIå†…å®¹åˆ†æç»“æœçš„ç…§ç‰‡ID
    """
    try:
        # åªæŸ¥æ‰¾æ²¡æœ‰contentåˆ†æè®°å½•çš„ç…§ç‰‡
        no_analysis_photos = db.query(Photo.id).filter(
            ~db.query(PhotoAnalysis).filter(
                PhotoAnalysis.photo_id == Photo.id,
                PhotoAnalysis.analysis_type == 'content'
            ).exists()
        ).all()
        
        photo_ids = [photo.id for photo in no_analysis_photos]
        
        logger.info(f"AIå¾…å¤„ç†ç…§ç‰‡ç»Ÿè®¡: æœªå¤„ç† {len(photo_ids)} å¼ ")
        
        return {
            "photo_ids": photo_ids,
            "total_count": len(photo_ids),
            "message": f"æ‰¾åˆ° {len(photo_ids)} å¼ éœ€è¦AIåˆ†æçš„ç…§ç‰‡"
        }
    except Exception as e:
        logger.error(f"è·å–AIåˆ†æç…§ç‰‡åˆ—è¡¨å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–AIåˆ†æç…§ç‰‡åˆ—è¡¨å¤±è´¥: {str(e)}")


@router.post("/photos/{photo_id}/analyze-ai")
async def analyze_photo_ai_sync(
    photo_id: int,
    db: Session = Depends(get_db)
):
    """
    åŒæ­¥åˆ†æå•å¼ ç…§ç‰‡çš„AIå†…å®¹
    
    - **photo_id**: è¦åˆ†æçš„ç…§ç‰‡ID
    """
    try:
        # éªŒè¯ç…§ç‰‡å­˜åœ¨
        photo = db.query(Photo).filter(Photo.id == photo_id).first()
        if not photo:
            raise HTTPException(status_code=404, detail="ç…§ç‰‡ä¸å­˜åœ¨")

        # è·å–åˆ†ææœåŠ¡
        analysis_service = AnalysisService()
        
        # åŒæ­¥æ‰§è¡ŒAIåˆ†æ
        logger.info(f"å¼€å§‹åŒæ­¥AIåˆ†æç…§ç‰‡: {photo_id}")
        result = await analysis_service.analyze_photo(
            photo_id=photo_id,
            analysis_types=['content'],
            db=db,
            original_status=photo.status
        )
        
        logger.info(f"ç…§ç‰‡ {photo_id} AIåˆ†æå®Œæˆ")
        
        return {
            "success": True,
            "photo_id": photo_id,
            "result": result,
            "message": "AIåˆ†æå®Œæˆ"
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åŒæ­¥AIåˆ†æå¤±è´¥ {photo_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"AIåˆ†æå¤±è´¥: {str(e)}")


@router.post("/start-analysis")
async def start_analysis(request: AnalysisRequest, background_tasks: BackgroundTasks, db: Session = Depends(get_db)):
    """
    å¼€å§‹æ¡ä»¶åˆ†æï¼ˆæ”¯æŒåŸºç¡€åˆ†æå’ŒAIåˆ†æï¼‰
    æ ¹æ®analysis_typeså‚æ•°åªæ‰§è¡ŒæŒ‡å®šçš„åˆ†æç±»å‹
    """
    try:
        logger.info(f"=== å¼€å§‹æ¡ä»¶åˆ†æ ===")
        logger.info(f"åˆ†æç±»å‹: {request.analysis_types}")
        logger.info(f"ç…§ç‰‡æ•°é‡: {len(request.photo_ids)}")
        logger.info(f"å¼ºåˆ¶é‡æ–°å¤„ç†: {request.force_reprocess}")

        # éªŒè¯åˆ†æç±»å‹ï¼ˆåªæ”¯æŒAIå†…å®¹åˆ†æï¼‰
        valid_types = ['content']
        invalid_types = [t for t in request.analysis_types if t not in valid_types]
        if invalid_types:
            raise HTTPException(status_code=400, detail=f"æ— æ•ˆçš„åˆ†æç±»å‹: {invalid_types}ï¼Œæ”¯æŒçš„ç±»å‹: {valid_types}")

        # è·å–åˆ†ææœåŠ¡
        analysis_service = AnalysisService()

        # è¿‡æ»¤éœ€è¦åˆ†æçš„ç…§ç‰‡
        if request.force_reprocess:
            # å¼ºåˆ¶é‡æ–°å¤„ç†æ‰€æœ‰æŒ‡å®šçš„ç…§ç‰‡
            photos_to_analyze = request.photo_ids
        else:
            # åªå¤„ç†è¿˜æ²¡æœ‰å¯¹åº”åˆ†æç»“æœçš„ç…§ç‰‡
            photos_to_analyze = []
            for photo_id in request.photo_ids:
                needs_analysis = False

                if 'content' in request.analysis_types:
                    # æ£€æŸ¥æ˜¯å¦æœ‰å†…å®¹åˆ†æç»“æœ
                    has_content = db.query(PhotoAnalysis).filter(
                        PhotoAnalysis.photo_id == photo_id,
                        PhotoAnalysis.analysis_type == 'content'
                    ).first() is not None
                    if not has_content:
                        needs_analysis = True

                if needs_analysis:
                    photos_to_analyze.append(photo_id)

        if not photos_to_analyze:
            return {
                "task_id": None,
                "total_photos": 0,
                "message": "æ‰€æœ‰ç…§ç‰‡éƒ½å·²å®ŒæˆæŒ‡å®šç±»å‹çš„åˆ†æ"
            }

        logger.info(f"å®é™…éœ€è¦åˆ†æçš„ç…§ç‰‡: {len(photos_to_analyze)} å¼ ")

        # è®°å½•åŸå§‹çŠ¶æ€å¹¶è®¾ç½®ä¸ºanalyzingçŠ¶æ€
        original_statuses = {}
        for photo_id in photos_to_analyze:
            photo = db.query(Photo).filter(Photo.id == photo_id).first()
            if photo:
                original_statuses[photo_id] = photo.status  # è®°å½•åŸå§‹çŠ¶æ€
                photo.status = 'analyzing'  # ä»»ä½•åˆ†æè¿‡ç¨‹ä¸­éƒ½è®¾ä¸ºanalyzing
                logger.info(f"ç…§ç‰‡ {photo_id} çŠ¶æ€ä» {original_statuses[photo_id]} è®¾ä¸º analyzing")
        
        db.commit()
        
        # å°†åŸå§‹çŠ¶æ€ä¼ é€’ç»™åå°ä»»åŠ¡
        task_original_statuses = original_statuses

        # ç”Ÿæˆä»»åŠ¡ID
        import uuid
        task_id = str(uuid.uuid4())

        # æ·»åŠ åå°ä»»åŠ¡
        background_tasks.add_task(
            process_analysis_task,
            task_id=task_id,
            photo_ids=photos_to_analyze,
            analysis_types=request.analysis_types,
            original_statuses=task_original_statuses
        )

        return {
            "task_id": task_id,
            "total_photos": len(photos_to_analyze),
            "analysis_types": request.analysis_types,
            "message": f"å·²å¼€å§‹åˆ†æ {len(photos_to_analyze)} å¼ ç…§ç‰‡"
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å¼€å§‹æ¡ä»¶åˆ†æå¤±è´¥: {str(e)}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"å¼€å§‹æ¡ä»¶åˆ†æå¤±è´¥: {str(e)}")


@router.get("/task-status/{task_id}")
async def get_analysis_task_status(task_id: str, initial_total: int = None, db: Session = Depends(get_db)):
    """
    è·å–åˆ†æä»»åŠ¡çŠ¶æ€
    æ”¯æŒæ¡ä»¶åˆ†æçš„çŠ¶æ€æŸ¥è¯¢

    - **task_id**: ä»»åŠ¡ID
    - **initial_total**: ä»»åŠ¡å¼€å§‹æ—¶çš„å¾…å¤„ç†ç…§ç‰‡æ€»æ•°ï¼ˆimported + errorï¼‰
    """
    try:
        # ä¼˜å…ˆæ£€æŸ¥ä»»åŠ¡çŠ¶æ€è·Ÿè¸ªå­—å…¸
        task_data = analysis_task_status.get(task_id)
        if task_data:
            # ä»»åŠ¡å­˜åœ¨äºå†…å­˜ä¸­ï¼Œç›´æ¥è¿”å›ä»»åŠ¡çŠ¶æ€
            status = task_data["status"]
            total_photos = task_data["total_photos"]
            completed_photos = task_data["completed_photos"]
            failed_photos = task_data["failed_photos"]
            progress_percentage = task_data["progress_percentage"]
            processing_photos = total_photos - completed_photos - failed_photos

            return {
                "task_id": task_id,
                "status": status,
                "total_photos": total_photos,
                "completed_photos": completed_photos,
                "failed_photos": failed_photos,
                "progress_percentage": round(progress_percentage, 2),
                "processing_photos": processing_photos
            }

        # ä»»åŠ¡ä¸å­˜åœ¨äºå†…å­˜ä¸­ï¼ˆå¯èƒ½å·²æ¸…ç†æˆ–ä»æœªå¯åŠ¨ï¼‰ï¼Œå›é€€åˆ°æ•°æ®åº“ç»Ÿè®¡
        logger.warning(f"ä»»åŠ¡ {task_id} çŠ¶æ€ä¸å­˜åœ¨äºå†…å­˜ä¸­ï¼Œå›é€€åˆ°æ•°æ®åº“ç»Ÿè®¡")

        # è·å–å½“å‰æ•°æ®åº“ä¸­çš„ç»Ÿè®¡ä¿¡æ¯
        imported_count = db.query(Photo).filter(Photo.status == 'imported').count()
        error_count = db.query(Photo).filter(Photo.status == 'error').count()
        analyzing_count = db.query(Photo).filter(Photo.status == 'analyzing').count()
        completed_count = db.query(Photo).filter(Photo.status == 'completed').count()

        # å½“å‰å¾…å¤„ç†çš„ç…§ç‰‡æ€»æ•°ï¼ˆimported + errorï¼‰
        current_pending_total = imported_count + error_count

        # ä½¿ç”¨æä¾›çš„ initial_total ä½œä¸ºåˆ†æ¯ï¼ˆå¦‚æœæä¾›çš„è¯ï¼‰
        display_total = initial_total if initial_total is not None else current_pending_total

        # å›é€€é€»è¾‘ï¼šåŸºäºæ•°æ®åº“ç»Ÿè®¡ä¼°ç®—çŠ¶æ€
        if analyzing_count == 0:
            # æ²¡æœ‰æ­£åœ¨åˆ†æçš„ç…§ç‰‡ï¼Œè®¤ä¸ºä»»åŠ¡å·²å®Œæˆ
            status = "completed"
            # å·²å®Œæˆçš„ç…§ç‰‡æ•°åŸºäºæ•°æ®åº“ç»Ÿè®¡
            completed_photos = completed_count
            failed_photos = 0
        else:
            # æœ‰ç…§ç‰‡æ­£åœ¨åˆ†æï¼Œè®¤ä¸ºä»»åŠ¡è¿›è¡Œä¸­
            status = "processing"
            # å·²å®Œæˆçš„ç…§ç‰‡æ•°åŸºäºæ•°æ®åº“ç»Ÿè®¡
            completed_photos = completed_count
            failed_photos = 0

        progress_percentage = (completed_photos / display_total * 100) if display_total > 0 else 100

        return {
            "task_id": task_id,
            "status": status,
            "total_photos": display_total,
            "completed_photos": completed_photos,
            "failed_photos": failed_photos,
            "progress_percentage": round(progress_percentage, 2),
            "processing_photos": analyzing_count
        }

    except Exception as e:
        logger.error(f"è·å–åˆ†æçŠ¶æ€å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–åˆ†æçŠ¶æ€å¤±è´¥: {str(e)}")


# æ‰¹é‡çŠ¶æ€æŸ¥è¯¢è¯·æ±‚æ¨¡å‹
class BatchStatusRequest(BaseModel):
    """æ‰¹é‡åˆ†æä»»åŠ¡çŠ¶æ€æŸ¥è¯¢è¯·æ±‚"""
    task_ids: List[str] = Field(..., description="ä»»åŠ¡IDåˆ—è¡¨")
    initial_totals: Optional[Dict[str, int]] = Field(None, description="å„ä»»åŠ¡çš„åˆå§‹ç…§ç‰‡æ€»æ•° {task_id: count}")


@router.post("/batch-status")
async def get_analysis_batch_status(request: BatchStatusRequest, db: Session = Depends(get_db)):
    """
    è·å–å¤šä¸ªåˆ†æä»»åŠ¡çš„èšåˆçŠ¶æ€ï¼ˆç±»ä¼¼å¯¼å…¥çš„batch-statusï¼‰

    ä½¿ç”¨ä»»åŠ¡çŠ¶æ€å­—å…¸æŸ¥è¯¢ï¼Œé¿å…å‰ç«¯å‘èµ·è¿‡å¤šå¹¶å‘è¯·æ±‚
    """
    try:
        logger.info(f"æ‰¹é‡æŸ¥è¯¢åˆ†æä»»åŠ¡çŠ¶æ€ï¼Œä»»åŠ¡æ•°é‡: {len(request.task_ids)}")

        if not request.task_ids:
            raise HTTPException(status_code=400, detail="ä»»åŠ¡IDåˆ—è¡¨ä¸èƒ½ä¸ºç©º")

        batch_results = []
        total_completed_photos = 0
        total_analyzing_photos = 0
        total_failed_photos = 0
        completed_tasks = 0

        # æŸ¥è¯¢æ¯ä¸ªä»»åŠ¡çš„çŠ¶æ€ - ä½¿ç”¨ä»»åŠ¡çŠ¶æ€å­—å…¸
        for task_id in request.task_ids:
            try:
                # ä»ä»»åŠ¡çŠ¶æ€å­—å…¸è·å–ä»»åŠ¡çŠ¶æ€
                task_data = analysis_task_status.get(task_id)

                if task_data:
                    # ä»»åŠ¡å­˜åœ¨ï¼Œä½¿ç”¨ä»»åŠ¡çŠ¶æ€
                    status = task_data["status"]
                    total_photos = task_data["total_photos"]
                    completed_photos = task_data["completed_photos"]
                    failed_photos = task_data["failed_photos"]
                    progress_percentage = task_data["progress_percentage"]
                    processing_photos = total_photos - completed_photos - failed_photos
                else:
                    # ä»»åŠ¡ä¸å­˜åœ¨ï¼ˆå¯èƒ½å·²æ¸…ç†æˆ–ä»æœªå¯åŠ¨ï¼‰ï¼Œæ ‡è®°ä¸ºé”™è¯¯
                    logger.warning(f"ä»»åŠ¡ {task_id} çŠ¶æ€ä¸å­˜åœ¨")
                    status = "error"
                    total_photos = 0
                    completed_photos = 0
                    failed_photos = 0
                    progress_percentage = 0
                    processing_photos = 0

                task_result = {
                    "task_id": task_id,
                    "status": status,
                    "total_photos": total_photos,
                    "completed_photos": completed_photos,
                    "failed_photos": failed_photos,
                    "progress_percentage": round(progress_percentage, 2),
                    "processing_photos": processing_photos
                }

                batch_results.append(task_result)

                # ç´¯ç§¯ç»Ÿè®¡
                total_completed_photos += completed_photos
                total_analyzing_photos += processing_photos
                total_failed_photos += failed_photos

                if status == "completed":
                    completed_tasks += 1

            except Exception as e:
                logger.warning(f"æŸ¥è¯¢ä»»åŠ¡ {task_id} çŠ¶æ€å¤±è´¥: {str(e)}")
                # ä»»åŠ¡æŸ¥è¯¢å¤±è´¥ï¼Œè®°å½•ä¸ºé”™è¯¯çŠ¶æ€
                batch_results.append({
                    "task_id": task_id,
                    "status": "error",
                    "error": str(e),
                    "total_photos": 0,
                    "completed_photos": 0,
                    "failed_photos": 0,
                    "progress_percentage": 0,
                    "processing_photos": 0
                })

        # è®¡ç®—æ€»ä½“çŠ¶æ€
        total_tasks = len(request.task_ids)
        overall_progress = (completed_tasks / total_tasks * 100) if total_tasks > 0 else 0

        # æ€»ä½“çŠ¶æ€åˆ¤æ–­ï¼šæ‰€æœ‰ä»»åŠ¡éƒ½å®Œæˆæ‰ç®—å®Œæˆ
        overall_status = "completed" if completed_tasks == total_tasks else "processing"

        result = {
            "overall_status": overall_status,
            "overall_progress_percentage": round(overall_progress, 2),
            "completed_tasks": completed_tasks,
            "total_tasks": total_tasks,
            "total_completed_photos": total_completed_photos,
            "total_analyzing_photos": total_analyzing_photos,
            "total_failed_photos": total_failed_photos,
            "task_details": batch_results
        }

        logger.info(f"åˆ†ææ‰¹æ¬¡èšåˆçŠ¶æ€: {completed_tasks}/{total_tasks} å®Œæˆï¼Œæ€»ä½“è¿›åº¦: {overall_progress}%")
        return result

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ‰¹é‡æŸ¥è¯¢åˆ†æä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡æŸ¥è¯¢åˆ†æä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")


async def process_analysis_task(task_id: str, photo_ids: List[int], analysis_types: List[str], original_statuses: Dict[int, str] = None):
    """
    å¤„ç†åˆ†æä»»åŠ¡ï¼ˆåå°ä»»åŠ¡ï¼‰- ä½¿ç”¨asyncioå¹¶å‘å¤„ç†
    æ”¯æŒä¸¤ç§æ¨¡å¼ï¼šå¯¼èˆªæ æ‰¹æ¬¡å¤„ç†å’Œé€‰ä¸­ç…§ç‰‡å•æ¬¡å¤„ç†
    """
    logger.info(f"=== å¼€å§‹å¤„ç†åˆ†æä»»åŠ¡ {task_id} ===")
    logger.info(f"ç…§ç‰‡æ•°é‡: {len(photo_ids)}, åˆ†æç±»å‹: {analysis_types}")

    # åˆ›å»ºæ•°æ®åº“ä¼šè¯
    db = next(get_db())

    # ä½¿ç”¨ä¼ å…¥çš„åŸå§‹çŠ¶æ€ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä»æ•°æ®åº“è·å–
    if original_statuses is None:
        original_statuses = {}
        for photo_id in photo_ids:
            photo = db.query(Photo).filter(Photo.id == photo_id).first()
            if photo:
                original_statuses[photo_id] = photo.status

    # åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€
    analysis_task_status[task_id] = {
        "status": "processing",
        "total_photos": len(photo_ids),
        "completed_photos": 0,
        "failed_photos": 0,
        "progress_percentage": 0.0,
        "start_time": datetime.now().isoformat(),
        "analysis_types": analysis_types,
        "error_details": [],  # æ–°å¢ï¼šè®°å½•å…·ä½“é”™è¯¯ä¿¡æ¯
        "original_statuses": original_statuses  # æ–°å¢ï¼šè®°å½•åŸå§‹çŠ¶æ€
    }

    try:
        analysis_service = AnalysisService()
        
        # ğŸ”¥ å…³é”®æ”¹è¿›ï¼šä½¿ç”¨ç°æœ‰é…ç½®çš„å¹¶å‘æ•°
        from app.core.config import settings
        max_concurrent = settings.analysis.concurrent  # ä½¿ç”¨ç°æœ‰çš„concurrenté…ç½®
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def analyze_single_photo_with_semaphore(photo_id: int):
            """ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘å¤„ç†å•å¼ ç…§ç‰‡"""
            async with semaphore:
                try:
                    # logger.info(f"å¼€å§‹åˆ†æç…§ç‰‡ {photo_id}")
                    original_status = original_statuses.get(photo_id, 'imported')
                    result = await analysis_service.analyze_photo(
                        photo_id, analysis_types, db, original_status
                    )
                    # logger.info(f"ç…§ç‰‡ {photo_id} åˆ†æå®Œæˆ")
                    return {"photo_id": photo_id, "status": "success", "result": result}
                    
                except Exception as e:
                    logger.error(f"ç…§ç‰‡ {photo_id} åˆ†æå¤±è´¥: {str(e)}")
                    
                    # ä¿å­˜é”™è¯¯ä¿¡æ¯å¹¶æ¢å¤åŸå§‹çŠ¶æ€
                    error_info = {
                        "error": str(e),
                        "error_type": "analysis_error",
                        "failed_at": datetime.now().isoformat()
                    }
                    original_status = original_statuses.get(photo_id, 'imported')
                    analysis_service._save_error_result(
                        photo_id, error_info, db, original_status, 
                        analysis_types[0] if analysis_types else None
                    )
                    
                    return {"photo_id": photo_id, "status": "error", "error": str(e)}
        
        # ğŸ”¥ å…³é”®æ”¹è¿›ï¼šå¹¶å‘æ‰§è¡Œæ‰€æœ‰åˆ†æä»»åŠ¡
        logger.info(f"å¼€å§‹å¹¶å‘åˆ†æ {len(photo_ids)} å¼ ç…§ç‰‡ï¼Œæœ€å¤§å¹¶å‘æ•°: {max_concurrent}")
        tasks = [analyze_single_photo_with_semaphore(photo_id) for photo_id in photo_ids]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†ç»“æœå’Œæ›´æ–°çŠ¶æ€
        successful_analyses = 0
        failed_analyses = 0
        
        for result in results:
            if isinstance(result, Exception):
                failed_analyses += 1
                logger.error(f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {str(result)}")
                continue
                
            if result["status"] == "success":
                successful_analyses += 1
            else:
                failed_analyses += 1
                analysis_task_status[task_id]["error_details"].append({
                    "photo_id": result["photo_id"],
                    "error": result["error"],
                    "error_type": "analysis_error",
                    "timestamp": datetime.now().isoformat()
                })

        # æ›´æ–°æœ€ç»ˆçŠ¶æ€
        analysis_task_status[task_id].update({
            "status": "completed",
            "completed_photos": successful_analyses,
            "failed_photos": failed_analyses,
            "end_time": datetime.now().isoformat(),
            "progress_percentage": 100.0
        })

        logger.info(f"=== åˆ†æä»»åŠ¡ {task_id} å®Œæˆ ===")
        logger.info(f"æˆåŠŸ: {successful_analyses}, å¤±è´¥: {failed_analyses}")

        # å»¶è¿Ÿæ¸…ç†ä»»åŠ¡çŠ¶æ€ï¼Œé¿å…å†…å­˜æ³„æ¼
        async def cleanup_task_status():
            await asyncio.sleep(TASK_STATUS_CLEANUP_HOURS * 3600)  # å»¶è¿Ÿæ¸…ç†
            if task_id in analysis_task_status:
                del analysis_task_status[task_id]
                logger.info(f"æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡çŠ¶æ€: {task_id}")

        # å¯åŠ¨åå°æ¸…ç†ä»»åŠ¡
        asyncio.create_task(cleanup_task_status())

    except Exception as e:
        logger.error(f"å¤„ç†åˆ†æä»»åŠ¡å¤±è´¥: {str(e)}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")

        # æ ‡è®°ä»»åŠ¡å¤±è´¥
        analysis_task_status[task_id].update({
            "status": "failed",
            "error": str(e),
            "end_time": datetime.now().isoformat()
        })
    finally:
        try:
            db.close()
        except:
            pass



